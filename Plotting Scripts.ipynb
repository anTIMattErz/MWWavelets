{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# NE Climate Database #\n",
    "### Plotting Scripts ###\n",
    "\n",
    "This file collects the plotting scripts from the NE Climate Database file. Plotting will be done in this file, to ease the clutter from the original file. Because IPython notebooks are not \"raw\" .py files, we first require a handful of methods/classes to import the MWWavelets modules (notebook) that contains all of the wavelet methods."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Scripts taken from: http://jupyter-notebook.readthedocs.io/en/latest/examples/Notebook/Importing%20Notebooks.html\n",
    "import io, os, sys, types\n",
    "from IPython import get_ipython\n",
    "from nbformat import read\n",
    "from IPython.core.interactiveshell import InteractiveShell"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def find_notebook(fullname, path=None):\n",
    "    \"\"\"find a notebook, given its fully qualified name and an optional path\n",
    "\n",
    "    This turns \"foo.bar\" into \"foo/bar.ipynb\"\n",
    "    and tries turning \"Foo_Bar\" into \"Foo Bar\" if Foo_Bar\n",
    "    does not exist.\n",
    "    \"\"\"\n",
    "    name = fullname.rsplit('.', 1)[-1]\n",
    "    if not path:\n",
    "        path = ['']\n",
    "    for d in path:\n",
    "        nb_path = os.path.join(d, name + \".ipynb\")\n",
    "        if os.path.isfile(nb_path):\n",
    "            return nb_path\n",
    "        # let import Notebook_Name find \"Notebook Name.ipynb\"\n",
    "        nb_path = nb_path.replace(\"_\", \" \")\n",
    "        if os.path.isfile(nb_path):\n",
    "            return nb_path\n",
    "        \n",
    "class NotebookLoader(object):\n",
    "    \"\"\"Module Loader for Jupyter Notebooks\"\"\"\n",
    "    def __init__(self, path=None):\n",
    "        self.shell = InteractiveShell.instance()\n",
    "        self.path = path\n",
    "\n",
    "    def load_module(self, fullname):\n",
    "        \"\"\"import a notebook as a module\"\"\"\n",
    "        path = find_notebook(fullname, self.path)\n",
    "\n",
    "        print (\"importing Jupyter notebook from %s\" % path)\n",
    "\n",
    "        # load the notebook object\n",
    "        with io.open(path, 'r', encoding='utf-8') as f:\n",
    "            nb = read(f, 4)\n",
    "\n",
    "\n",
    "        # create the module and add it to sys.modules\n",
    "        # if name in sys.modules:\n",
    "        #    return sys.modules[name]\n",
    "        mod = types.ModuleType(fullname)\n",
    "        mod.__file__ = path\n",
    "        mod.__loader__ = self\n",
    "        mod.__dict__['get_ipython'] = get_ipython\n",
    "        sys.modules[fullname] = mod\n",
    "\n",
    "        # extra work to ensure that magics that would affect the user_ns\n",
    "        # actually affect the notebook module's ns\n",
    "        save_user_ns = self.shell.user_ns\n",
    "        self.shell.user_ns = mod.__dict__\n",
    "\n",
    "        try:\n",
    "          for cell in nb.cells:\n",
    "            if cell.cell_type == 'code':\n",
    "                # transform the input to executable Python\n",
    "                code = self.shell.input_transformer_manager.transform_cell(cell.source)\n",
    "                # run the code in themodule\n",
    "                exec(code, mod.__dict__)\n",
    "        finally:\n",
    "            self.shell.user_ns = save_user_ns\n",
    "        return mod\n",
    "    \n",
    "class NotebookFinder(object):\n",
    "    \"\"\"Module finder that locates Jupyter Notebooks\"\"\"\n",
    "    def __init__(self):\n",
    "        self.loaders = {}\n",
    "\n",
    "    def find_module(self, fullname, path=None):\n",
    "        nb_path = find_notebook(fullname, path)\n",
    "        if not nb_path:\n",
    "            return\n",
    "\n",
    "        key = path\n",
    "        if path:\n",
    "            # lists aren't hashable\n",
    "            key = os.path.sep.join(path)\n",
    "\n",
    "        if key not in self.loaders:\n",
    "            self.loaders[key] = NotebookLoader(path)\n",
    "        return self.loaders[key]\n",
    "\n",
    "sys.meta_path.append(NotebookFinder())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Importing MWWavelets\n",
    "Imports the methods required to apply the transforms. Also constructs the NE Climate database."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "importing Jupyter notebook from MWWavelets.ipynb\n",
      "checkpoint 1\n",
      "checkpoint 2\n",
      "Completed Initilization of StateID Object:  62658\n",
      "Completed Initilization of StateID Object:  63207\n",
      "Completed Initilization of StateID Object:  67970\n",
      "Completed Initilization of StateID Object:  68138\n",
      "Completed Initilization of StateID Object:  170100\n",
      "Completed Initilization of StateID Object:  170814\n",
      "Completed Initilization of StateID Object:  171628\n",
      "Completed Initilization of StateID Object:  172426\n",
      "Completed Initilization of StateID Object:  172765\n",
      "Completed Initilization of StateID Object:  173046\n",
      "Cleaning at ID:  173944\n",
      "Year: 1901   Value: -9999.0\n",
      "Set to:  0\n",
      "Cleaning at ID:  173944\n",
      "Year: 1901   Value: -9999.0\n",
      "Set to:  0\n",
      "Completed Initilization of StateID Object:  173944\n",
      "Completed Initilization of StateID Object:  174566\n",
      "Completed Initilization of StateID Object:  175304\n",
      "Completed Initilization of StateID Object:  176905\n",
      "Cleaning at ID:  176937\n",
      "Year: 1900   Value: -9999.0\n",
      "Set to:  0\n",
      "Cleaning at ID:  176937\n",
      "Year: 1900   Value: -9999.0\n",
      "Set to:  0\n",
      "Cleaning at ID:  176937\n",
      "Year: 1900   Value: -9999.0\n",
      "Set to:  0\n",
      "Cleaning at ID:  176937\n",
      "Year: 1900   Value: -9999.0\n",
      "Set to:  0\n",
      "Cleaning at ID:  176937\n",
      "Year: 1900   Value: -9999.0\n",
      "Set to:  0\n",
      "Cleaning at ID:  176937\n",
      "Year: 1900   Value: -9999.0\n",
      "Set to:  0\n",
      "Cleaning at ID:  176937\n",
      "Year: 1900   Value: -9999.0\n",
      "Set to:  0\n",
      "Cleaning at ID:  176937\n",
      "Year: 1900   Value: -9999.0\n",
      "Set to:  0\n",
      "Cleaning at ID:  176937\n",
      "Year: 1900   Value: -9999.0\n",
      "Set to:  0\n",
      "Cleaning at ID:  176937\n",
      "Year: 1900   Value: -9999.0\n",
      "Set to:  0\n",
      "Cleaning at ID:  176937\n",
      "Year: 1900   Value: -9999.0\n",
      "Set to:  0\n",
      "Cleaning at ID:  176937\n",
      "Year: 1900   Value: -9999.0\n",
      "Set to:  0\n",
      "Cleaning at ID:  176937\n",
      "Year: 1901   Value: -9999.0\n",
      "Set to:  0\n",
      "Cleaning at ID:  176937\n",
      "Year: 1901   Value: -9999.0\n",
      "Set to:  0\n",
      "Cleaning at ID:  176937\n",
      "Year: 1901   Value: -9999.0\n",
      "Set to:  0\n",
      "Cleaning at ID:  176937\n",
      "Year: 1901   Value: -9999.0\n",
      "Set to:  0\n",
      "Cleaning at ID:  176937\n",
      "Year: 1901   Value: -9999.0\n",
      "Set to:  0\n",
      "Cleaning at ID:  176937\n",
      "Year: 1901   Value: -9999.0\n",
      "Set to:  0\n",
      "Cleaning at ID:  176937\n",
      "Year: 1901   Value: -9999.0\n",
      "Set to:  0\n",
      "Cleaning at ID:  176937\n",
      "Year: 1901   Value: -9999.0\n",
      "Set to:  0\n",
      "Cleaning at ID:  176937\n",
      "Year: 1901   Value: -9999.0\n",
      "Set to:  0\n",
      "Cleaning at ID:  176937\n",
      "Year: 1901   Value: -9999.0\n",
      "Set to:  0\n",
      "Cleaning at ID:  176937\n",
      "Year: 1901   Value: -9999.0\n",
      "Set to:  0\n",
      "Cleaning at ID:  176937\n",
      "Year: 1901   Value: -9999.0\n",
      "Set to:  0\n",
      "Cleaning at ID:  176937\n",
      "Year: 1901   Value: -9999.0\n",
      "Set to:  0\n",
      "Cleaning at ID:  176937\n",
      "Year: 1901   Value: -9999.0\n",
      "Set to:  0\n",
      "Cleaning at ID:  176937\n",
      "Year: 1901   Value: -9999.0\n",
      "Set to:  0\n",
      "Cleaning at ID:  176937\n",
      "Year: 1901   Value: -9999.0\n",
      "Set to:  0\n",
      "Cleaning at ID:  176937\n",
      "Year: 1901   Value: -9999.0\n",
      "Set to:  0\n",
      "Cleaning at ID:  176937\n",
      "Year: 1901   Value: -9999.0\n",
      "Set to:  0\n",
      "Cleaning at ID:  176937\n",
      "Year: 1901   Value: -9999.0\n",
      "Set to:  0\n",
      "Cleaning at ID:  176937\n",
      "Year: 1901   Value: -9999.0\n",
      "Set to:  0\n",
      "Cleaning at ID:  176937\n",
      "Year: 1901   Value: -9999.0\n",
      "Set to:  0\n",
      "Cleaning at ID:  176937\n",
      "Year: 1901   Value: -9999.0\n",
      "Set to:  0\n",
      "Cleaning at ID:  176937\n",
      "Year: 1901   Value: -9999.0\n",
      "Set to:  0\n",
      "Cleaning at ID:  176937\n",
      "Year: 1901   Value: -9999.0\n",
      "Set to:  0\n",
      "Cleaning at ID:  176937\n",
      "Year: 1901   Value: -9999.0\n",
      "Set to:  0\n",
      "Cleaning at ID:  176937\n",
      "Year: 1901   Value: -9999.0\n",
      "Set to:  0\n",
      "Cleaning at ID:  176937\n",
      "Year: 1902   Value: -9999.0\n",
      "Set to:  0\n",
      "Cleaning at ID:  176937\n",
      "Year: 1902   Value: -9999.0\n",
      "Set to:  0\n",
      "Cleaning at ID:  176937\n",
      "Year: 1902   Value: -9999.0\n",
      "Set to:  0\n",
      "Cleaning at ID:  176937\n",
      "Year: 1902   Value: -9999.0\n",
      "Set to:  0\n",
      "Cleaning at ID:  176937\n",
      "Year: 1902   Value: -9999.0\n",
      "Set to:  0\n",
      "Cleaning at ID:  176937\n",
      "Year: 1902   Value: -9999.0\n",
      "Set to:  0\n",
      "Cleaning at ID:  176937\n",
      "Year: 1902   Value: -9999.0\n",
      "Set to:  0\n",
      "Cleaning at ID:  176937\n",
      "Year: 1902   Value: -9999.0\n",
      "Set to:  0\n",
      "Cleaning at ID:  176937\n",
      "Year: 1902   Value: -9999.0\n",
      "Set to:  0\n",
      "Completed Initilization of StateID Object:  176937\n",
      "Completed Initilization of StateID Object:  179891\n",
      "Completed Initilization of StateID Object:  190120\n",
      "Completed Initilization of StateID Object:  190535\n",
      "Completed Initilization of StateID Object:  190736\n",
      "Cleaning at ID:  193213\n",
      "Year: 1900   Value: -9999.0\n",
      "Set to:  0\n",
      "Cleaning at ID:  193213\n",
      "Year: 1900   Value: -9999.0\n",
      "Set to:  0\n",
      "Cleaning at ID:  193213\n",
      "Year: 1900   Value: -9999.0\n",
      "Set to:  0\n",
      "Cleaning at ID:  193213\n",
      "Year: 1900   Value: -9999.0\n",
      "Set to:  0\n",
      "Cleaning at ID:  193213\n",
      "Year: 1901   Value: -9999.0\n",
      "Set to:  0\n",
      "Cleaning at ID:  193213\n",
      "Year: 1901   Value: -9999.0\n",
      "Set to:  0\n",
      "Cleaning at ID:  193213\n",
      "Year: 1901   Value: -9999.0\n",
      "Set to:  0\n",
      "Cleaning at ID:  193213\n",
      "Year: 1901   Value: -9999.0\n",
      "Set to:  0\n",
      "Cleaning at ID:  193213\n",
      "Year: 1901   Value: -9999.0\n",
      "Set to:  0\n",
      "Cleaning at ID:  193213\n",
      "Year: 1901   Value: -9999.0\n",
      "Set to:  0\n",
      "Cleaning at ID:  193213\n",
      "Year: 1901   Value: -9999.0\n",
      "Set to:  0\n",
      "Cleaning at ID:  193213\n",
      "Year: 1902   Value: -9999.0\n",
      "Set to:  0\n",
      "Cleaning at ID:  193213\n",
      "Year: 1902   Value: -9999.0\n",
      "Set to:  0\n",
      "Cleaning at ID:  193213\n",
      "Year: 1902   Value: -9999.0\n",
      "Set to:  0\n",
      "Cleaning at ID:  193213\n",
      "Year: 1902   Value: -9999.0\n",
      "Set to:  0\n",
      "Cleaning at ID:  193213\n",
      "Year: 1902   Value: -9999.0\n",
      "Set to:  0\n",
      "Cleaning at ID:  193213\n",
      "Year: 1902   Value: -9999.0\n",
      "Set to:  0\n",
      "Cleaning at ID:  193213\n",
      "Year: 1902   Value: -9999.0\n",
      "Set to:  0\n",
      "Cleaning at ID:  193213\n",
      "Year: 1902   Value: -9999.0\n",
      "Set to:  0\n",
      "Cleaning at ID:  193213\n",
      "Year: 1902   Value: -9999.0\n",
      "Set to:  0\n",
      "Cleaning at ID:  193213\n",
      "Year: 1903   Value: -9999.0\n",
      "Set to:  0\n",
      "Completed Initilization of StateID Object:  193213\n",
      "Completed Initilization of StateID Object:  194105\n",
      "Completed Initilization of StateID Object:  195246\n",
      "Completed Initilization of StateID Object:  196486\n",
      "Completed Initilization of StateID Object:  196681\n",
      "Completed Initilization of StateID Object:  196783\n",
      "Completed Initilization of StateID Object:  198367\n",
      "Completed Initilization of StateID Object:  198757\n",
      "Completed Initilization of StateID Object:  199316\n",
      "Completed Initilization of StateID Object:  270706\n",
      "Completed Initilization of StateID Object:  272174\n",
      "Cleaning at ID:  272999\n",
      "Year: 1900   Value: -9999.0\n",
      "Set to:  0\n",
      "Cleaning at ID:  272999\n",
      "Year: 1900   Value: -9999.0\n",
      "Set to:  0\n",
      "Cleaning at ID:  272999\n",
      "Year: 1900   Value: -9999.0\n",
      "Set to:  0\n",
      "Cleaning at ID:  272999\n",
      "Year: 1900   Value: -9999.0\n",
      "Set to:  0\n",
      "Cleaning at ID:  272999\n",
      "Year: 1900   Value: -9999.0\n",
      "Set to:  0\n",
      "Cleaning at ID:  272999\n",
      "Year: 1900   Value: -9999.0\n",
      "Set to:  0\n",
      "Cleaning at ID:  272999\n",
      "Year: 1900   Value: -9999.0\n",
      "Set to:  0\n",
      "Cleaning at ID:  272999\n",
      "Year: 1900   Value: -9999.0\n",
      "Set to:  0\n",
      "Cleaning at ID:  272999\n",
      "Year: 1900   Value: -9999.0\n",
      "Set to:  0\n",
      "Cleaning at ID:  272999\n",
      "Year: 1900   Value: -9999.0\n",
      "Set to:  0\n",
      "Cleaning at ID:  272999\n",
      "Year: 1901   Value: -9999.0\n",
      "Set to:  0\n",
      "Cleaning at ID:  272999\n",
      "Year: 1901   Value: -9999.0\n",
      "Set to:  0\n",
      "Cleaning at ID:  272999\n",
      "Year: 1901   Value: -9999.0\n",
      "Set to:  0\n",
      "Cleaning at ID:  272999\n",
      "Year: 1901   Value: -9999.0\n",
      "Set to:  0\n",
      "Cleaning at ID:  272999\n",
      "Year: 1901   Value: -9999.0\n",
      "Set to:  0\n",
      "Cleaning at ID:  272999\n",
      "Year: 1902   Value: -9999.0\n",
      "Set to:  0\n",
      "Cleaning at ID:  272999\n",
      "Year: 1902   Value: -9999.0\n",
      "Set to:  0\n",
      "Cleaning at ID:  272999\n",
      "Year: 1902   Value: -9999.0\n",
      "Set to:  0\n",
      "Cleaning at ID:  272999\n",
      "Year: 1902   Value: -9999.0\n",
      "Set to:  0\n",
      "Cleaning at ID:  272999\n",
      "Year: 1902   Value: -9999.0\n",
      "Set to:  0\n",
      "Cleaning at ID:  272999\n",
      "Year: 1902   Value: -9999.0\n",
      "Set to:  0\n",
      "Cleaning at ID:  272999\n",
      "Year: 1902   Value: -9999.0\n",
      "Set to:  0\n",
      "Cleaning at ID:  272999\n",
      "Year: 1902   Value: -9999.0\n",
      "Set to:  0\n",
      "Cleaning at ID:  272999\n",
      "Year: 1902   Value: -9999.0\n",
      "Set to:  0\n",
      "Cleaning at ID:  272999\n",
      "Year: 1902   Value: -9999.0\n",
      "Set to:  0\n",
      "Cleaning at ID:  272999\n",
      "Year: 1903   Value: -9999.0\n",
      "Set to:  0\n",
      "Cleaning at ID:  272999\n",
      "Year: 1903   Value: -9999.0\n",
      "Set to:  0\n",
      "Completed Initilization of StateID Object:  272999\n",
      "Completed Initilization of StateID Object:  273850\n",
      "Completed Initilization of StateID Object:  274399\n",
      "Completed Initilization of StateID Object:  280325\n",
      "Completed Initilization of StateID Object:  280734\n",
      "Completed Initilization of StateID Object:  280907\n",
      "Completed Initilization of StateID Object:  281582\n",
      "Completed Initilization of StateID Object:  283029\n",
      "Completed Initilization of StateID Object:  283951\n",
      "Completed Initilization of StateID Object:  284229\n",
      "Completed Initilization of StateID Object:  284987\n",
      "Completed Initilization of StateID Object:  285728\n",
      "Completed Initilization of StateID Object:  286055\n",
      "Completed Initilization of StateID Object:  287079\n",
      "Completed Initilization of StateID Object:  288816\n",
      "Completed Initilization of StateID Object:  300023\n",
      "Completed Initilization of StateID Object:  300042\n",
      "Completed Initilization of StateID Object:  300085\n",
      "Completed Initilization of StateID Object:  300093\n",
      "Completed Initilization of StateID Object:  300183\n",
      "Completed Initilization of StateID Object:  300321\n",
      "Completed Initilization of StateID Object:  300443\n",
      "Completed Initilization of StateID Object:  300687\n",
      "Completed Initilization of StateID Object:  300889\n",
      "Completed Initilization of StateID Object:  300937\n",
      "Completed Initilization of StateID Object:  301012\n",
      "Completed Initilization of StateID Object:  301185\n",
      "Completed Initilization of StateID Object:  301401\n",
      "Completed Initilization of StateID Object:  301752\n",
      "Completed Initilization of StateID Object:  301799\n",
      "Completed Initilization of StateID Object:  301966\n",
      "Completed Initilization of StateID Object:  301974\n",
      "Completed Initilization of StateID Object:  302060\n",
      "Completed Initilization of StateID Object:  302129\n",
      "Completed Initilization of StateID Object:  302610\n",
      "Completed Initilization of StateID Object:  303033\n",
      "Completed Initilization of StateID Object:  303184\n",
      "Completed Initilization of StateID Object:  303259\n",
      "Completed Initilization of StateID Object:  303319\n",
      "Completed Initilization of StateID Object:  303773\n",
      "Completed Initilization of StateID Object:  304102\n",
      "Completed Initilization of StateID Object:  304174\n",
      "Completed Initilization of StateID Object:  304555\n",
      "Completed Initilization of StateID Object:  304647\n",
      "Completed Initilization of StateID Object:  304791\n",
      "Completed Initilization of StateID Object:  304796\n",
      "Completed Initilization of StateID Object:  304844\n",
      "Completed Initilization of StateID Object:  304912\n",
      "Completed Initilization of StateID Object:  304996\n",
      "Completed Initilization of StateID Object:  305113\n",
      "Completed Initilization of StateID Object:  305426\n",
      "Completed Initilization of StateID Object:  305512\n",
      "Completed Initilization of StateID Object:  305801\n",
      "Completed Initilization of StateID Object:  306085\n",
      "Completed Initilization of StateID Object:  306164\n",
      "Completed Initilization of StateID Object:  306314\n",
      "Completed Initilization of StateID Object:  306774\n",
      "Completed Initilization of StateID Object:  306820\n",
      "Completed Initilization of StateID Object:  307167\n",
      "Completed Initilization of StateID Object:  307484\n",
      "Completed Initilization of StateID Object:  307633\n",
      "Completed Initilization of StateID Object:  308248\n",
      "Completed Initilization of StateID Object:  308383\n",
      "Completed Initilization of StateID Object:  308600\n",
      "Completed Initilization of StateID Object:  308631\n",
      "Completed Initilization of StateID Object:  308737\n",
      "Completed Initilization of StateID Object:  308906\n",
      "Completed Initilization of StateID Object:  308910\n",
      "Completed Initilization of StateID Object:  308944\n",
      "Completed Initilization of StateID Object:  309000\n",
      "Completed Initilization of StateID Object:  309292\n",
      "Completed Initilization of StateID Object:  309670\n",
      "Completed Initilization of StateID Object:  360106\n",
      "Completed Initilization of StateID Object:  361354\n",
      "Completed Initilization of StateID Object:  362537\n",
      "Completed Initilization of StateID Object:  362682\n",
      "Completed Initilization of StateID Object:  363028\n",
      "Completed Initilization of StateID Object:  363526\n",
      "Completed Initilization of StateID Object:  364385\n",
      "Completed Initilization of StateID Object:  364896\n",
      "Completed Initilization of StateID Object:  365915\n",
      "Completed Initilization of StateID Object:  366233\n",
      "Completed Initilization of StateID Object:  366689\n",
      "Completed Initilization of StateID Object:  367029\n",
      "Completed Initilization of StateID Object:  367322\n",
      "Completed Initilization of StateID Object:  367477\n",
      "Completed Initilization of StateID Object:  367931\n",
      "Completed Initilization of StateID Object:  368449\n",
      "Completed Initilization of StateID Object:  368596\n",
      "Completed Initilization of StateID Object:  368905\n",
      "Completed Initilization of StateID Object:  369050\n",
      "Completed Initilization of StateID Object:  369298\n",
      "Completed Initilization of StateID Object:  369408\n",
      "Completed Initilization of StateID Object:  369464\n",
      "Completed Initilization of StateID Object:  369728\n",
      "Completed Initilization of StateID Object:  369933\n",
      "Completed Initilization of StateID Object:  370896\n",
      "Completed Initilization of StateID Object:  374266\n",
      "Completed Initilization of StateID Object:  376698\n",
      "Completed Initilization of StateID Object:  431081\n",
      "Completed Initilization of StateID Object:  431243\n",
      "Completed Initilization of StateID Object:  431360\n",
      "Completed Initilization of StateID Object:  431580\n",
      "Completed Initilization of StateID Object:  432769\n",
      "Completed Initilization of StateID Object:  437054\n",
      "Completed Initilization of StateID Object:  437607\n",
      "Completed Initilization of StateID Object:  437612\n",
      "Completed Initilization of Objects!\n",
      "[0.86237941, 2.117721569, 1.608463379, -1.711390114, 0, 0, 1.305917459, -0.785074336, -1.453419333, -0.524445127, -1.519106516, -0.242608153]\n",
      "Finished adding coordinates and elevation to StateIDs!\n",
      "Number of StateIDs West of Appalachians:  83\n",
      "Number of StateIDs East of Appalachians:  54\n",
      "[-0.24280984  0.00429764]\n",
      "[ 1.00389689 -0.04980348]\n",
      "[  4.55983071e-14   1.00000000e+00]\n",
      "[-0.35135629  0.00643545]\n",
      "[ 0.99904946 -0.04622672]\n",
      "[  4.55983071e-14   1.00000000e+00]\n",
      "[-0.1060901   0.00202484]\n",
      "[ 0.99989977  0.01383359]\n",
      "[  4.55983071e-14   1.00000000e+00]\n",
      "[-0.23341873  0.00425265]\n",
      "[ 1.00603878 -0.04713832]\n",
      "[  4.55983071e-14   1.00000000e+00]\n"
     ]
    }
   ],
   "source": [
    "from MWWavelets import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# this is creating and saving a list containing all of the USHCN IDs so that I can attach lat/long/altitude's to them.\n",
    "ID_collection = []\n",
    "for i in StateID_objects:\n",
    "    ID_collection.append(i.name())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Min long is : -80.37\n",
      "Max long is : -67.0\n"
     ]
    }
   ],
   "source": [
    "#minimum and maximum longitude for sorting purposes\n",
    "min_long = 9999\n",
    "max_long = -9999\n",
    "for i in StateID_objects:\n",
    "    current_long = i.coord()[1]\n",
    "    if min_long > current_long:\n",
    "        min_long = current_long\n",
    "    if max_long < current_long:\n",
    "        max_long = current_long\n",
    "        \n",
    "print(\"Min long is :\", min_long)\n",
    "print(\"Max long is :\", max_long)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Plotting the line to see if it is correct\n",
    "longitudes = np.linspace(-83.72, -66.51, 1000, endpoint=True)\n",
    "latitudes = [appalachian_coord(longitudes[i]) for i in range(len(longitudes))]\n",
    "\n",
    "plt.scatter(longitudes, latitudes)\n",
    "plt.xlabel(\"Longitude\")\n",
    "plt.ylabel(\"Latitude\")\n",
    "plt.title(\"Appalachian Mountain Range Coordinate Plot\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Processing and Displaying Data (Plotting Scripts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#plotting max temp data for 62658\n",
    "N = 1380\n",
    "x_val = np.linspace(1900, 2014+11.0/12, N, endpoint=True)\n",
    "temps = dict_to_list(select_id(62658, StateID_objects).max_temp())\n",
    "\n",
    "#previously 24, 27/2\n",
    "my_dpi = 96\n",
    "plt.figure(num=1, figsize=(11520/my_dpi, 4320/my_dpi), dpi=my_dpi)\n",
    "plt.subplot(211)\n",
    "plt.plot(x_val, temps)\n",
    "plt.xlim(1895, 2020)\n",
    "plt.xticks(np.arange(1900, 2016, 5))\n",
    "plt.xlabel(\"Year\")\n",
    "plt.ylabel(\"Z-score\")\n",
    "plt.title(\"Max Temp Data for 62658\")\n",
    "\n",
    "#plotting smoothed max temp data\n",
    "new_vals = gaussian_smoother(x_val, temps, 2.5)\n",
    "smoothed_x_vals = new_vals[0]\n",
    "smoothed_y_vals = new_vals[1]\n",
    "\n",
    "plt.subplot(212)\n",
    "plt.plot(smoothed_x_vals, smoothed_y_vals)\n",
    "plt.xlim(1895, 2020)\n",
    "plt.xticks(np.arange(1900, 2016, 5))\n",
    "plt.xlabel(\"Year\")\n",
    "plt.ylabel(\"Z-score\")\n",
    "plt.title(\"Smoothed Max Temp Data for 62658\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Index and Averaging Methods (Plotting Scripts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# testing NEI index and average_StateID_series\n",
    "# StateID_objects is a list of all the StateID objects from the data set\n",
    "N = 1380\n",
    "x_val = np.linspace(1900, 2014+11.0/12, N, endpoint=True)\n",
    "ID62658 = select_id(62658, StateID_objects)\n",
    "nei_index_62658 = nei_index(ID62658)\n",
    "\n",
    "plt.figure(num=1, figsize=(24, 27/2), dpi=80)\n",
    "plt.plot(x_val, nei_index_62658)\n",
    "plt.xlim(1895, 2020)\n",
    "plt.xticks(np.arange(1900, 2016, 5))\n",
    "plt.xlabel(\"Year\")\n",
    "plt.ylabel(\"Z-score\")\n",
    "plt.title(\"NEI Index for 62658\")\n",
    "plt.show()\n",
    "\n",
    "# averaging for all StateIDs\n",
    "lists = average_StateID_series(StateID_objects)\n",
    "avg_max_temps = lists[0]\n",
    "avg_min_temps = lists[1]\n",
    "avg_precips = lists[2]\n",
    "avg_nei = lists[3]\n",
    "\n",
    "plt.figure(figsize=(24,13))\n",
    "plt.subplot(2, 2, 1)\n",
    "plt.plot(x_val, avg_max_temps)\n",
    "plt.xlim(1895, 2020)\n",
    "plt.xticks(np.arange(1900, 2016, 10))\n",
    "plt.xlabel(\"Year\")\n",
    "plt.ylabel(\"Z-score\")\n",
    "title_string_raw = \"Average Max Temp Data for All StateIDs\"\n",
    "plt.title(title_string_raw)\n",
    "\n",
    "plt.subplot(2, 2, 2)\n",
    "plt.plot(x_val, avg_min_temps)\n",
    "plt.xlim(1895, 2020)\n",
    "plt.xticks(np.arange(1900, 2016, 10))\n",
    "plt.xlabel(\"Year\")\n",
    "plt.ylabel(\"Z-score\")\n",
    "title_string_raw = \"Average Min Temp Data for All StateIDs\"\n",
    "plt.title(title_string_raw)\n",
    "\n",
    "plt.subplot(2, 2, 3)\n",
    "plt.plot(x_val, avg_precips)\n",
    "plt.xlim(1895, 2020)\n",
    "plt.xticks(np.arange(1900, 2016, 10))\n",
    "plt.xlabel(\"Year\")\n",
    "plt.ylabel(\"Z-score\")\n",
    "title_string_raw = \"Average Precip Data for All StateIDs\"\n",
    "plt.title(title_string_raw)\n",
    "\n",
    "plt.subplot(2, 2, 4)\n",
    "plt.plot(x_val, avg_nei)\n",
    "plt.xlim(1895, 2020)\n",
    "plt.xticks(np.arange(1900, 2016, 10))\n",
    "plt.xlabel(\"Year\")\n",
    "plt.ylabel(\"Z-score\")\n",
    "title_string_raw = \"Average NEI Index Data for All StateIDs\"\n",
    "plt.title(title_string_raw)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Generating Noisy Data (Plotting Scripts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Red Noise Generator Example\n",
    "red_noise_x = np.linspace(0, 100, 100)\n",
    "red_noise_y = red_noise_generator(0.345084339548, 1, 100)\n",
    "\n",
    "plt.plot(red_noise_x, red_noise_y,'bx')\n",
    "plt.xlim(0, 100)\n",
    "plt.xticks(np.arange(0, 100, 5))\n",
    "plt.xlabel(\"Sequence Index\")\n",
    "plt.ylabel(\"Noise Value\")\n",
    "plt.title(\"Red Noise for r=0.345084339548, std_dev=1\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Noisy Line Generator\n",
    "noisy_x = np.linspace(0, 10, 100)\n",
    "noise = red_noise_generator(0.345084339548, 1, 100)\n",
    "line_y = line_generator(-5, 1, noisy_x)\n",
    "noisy_data = noisy_line_generator(noisy_x, line_y, noise)\n",
    "\n",
    "plt.plot(noisy_data[0], noisy_data[1])\n",
    "plt.plot(noisy_x, line_y)\n",
    "plt.xlim(0, 10)\n",
    "plt.xticks(np.arange(0, 10, 0.5))\n",
    "plt.xlabel(\"Sequence Index\")\n",
    "plt.ylabel(\"Y Value\")\n",
    "plt.title(\"Linear trend w/ Noisy Data\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Wavelets"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Sampled Morlet Wavelet Plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.0\n",
      "Wavelet period-year conversion is: 0.987645853221\n",
      "Number of required sampling points: 24.0\n"
     ]
    }
   ],
   "source": [
    "# plotting sampled Morlet wavelet\n",
    "mlt = Morlet_Wavelet(1, 2*np.pi)\n",
    "dt = (1.0/12.0)\n",
    "print(sum([np.absolute(i*i)*dt for i in mlt.morlet_function()]))\n",
    "\n",
    "x = np.linspace(-2, 2, 2*mlt.sampling_points()+1)\n",
    "y = np.real(mlt.morlet_function())\n",
    "z = np.imag(mlt.morlet_function())\n",
    "print(\"Wavelet period-year conversion is: \"+str(mlt.scale_to_year()))\n",
    "print(\"Number of required sampling points: \"+str(mlt.sampling_points()))\n",
    "\n",
    "plt.plot(x, y, 'b', x, z, 'g')\n",
    "plt.xlim(-3, 3)\n",
    "plt.xticks(np.arange(-3, 4))\n",
    "plt.xlabel(\"x\")\n",
    "plt.ylabel(\"Amplitude\")\n",
    "plt.title(\"Morlet Wavelet w/ F = 2*Pi\")\n",
    "save_string = 'sampled_morlet_wavelet'\n",
    "plt.savefig(save_string)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Sampled Harr Wavelet Plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.0\n",
      "Harr wavelet width is (in years): 2\n"
     ]
    }
   ],
   "source": [
    "# plotting Harr wavelet\n",
    "harr = Harr_Wavelet(2)\n",
    "s = harr.scale()\n",
    "x = np.linspace(0, 11, 12*s)\n",
    "y = harr.harr_function()\n",
    "dt = (1.0/12.0)\n",
    "print(sum([np.absolute(i*i)*dt for i in mlt.morlet_function()]))\n",
    "print(\"Harr wavelet width is (in years): \"+str(s))\n",
    "\n",
    "plt.plot(x, y, 'r')\n",
    "plt.xlim(0, 11)\n",
    "plt.xticks(np.arange(0, 12))\n",
    "plt.xlabel(\"x\")\n",
    "plt.ylabel(\"Harr Amplitude\")\n",
    "plt.title(\"Harr Wavelet Function\")\n",
    "\n",
    "save_string = 'sampled_harr_wavelet'\n",
    "plt.savefig(save_string)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Convolution Method Testing (Plotting Scripts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# testing that Harr wavelet convolution method works\n",
    "station = select_id(62658, StateID_objects)\n",
    "min_winter_temps_list = dict_to_list(station.max_temp_winter())\n",
    "N = len(min_winter_temps_list)\n",
    "x_list = np.linspace(1900, 2014+0.75, N, endpoint=True)\n",
    "scales = harr_scale_range((1.0/6.0), 10)\n",
    "transform_coefficients = continuous_transform_harr(min_winter_temps_list, scales)\n",
    "\n",
    "Z = transform_coefficients\n",
    "\n",
    "# 24,13 usually\n",
    "plt.figure(figsize=(6,8))\n",
    "plt.subplot(2, 1, 1)\n",
    "plt.plot(x_list, min_winter_temps_list)\n",
    "plt.xlim(1895, 2020)\n",
    "plt.xticks(np.arange(1900, 2016, 20))\n",
    "# plt.xlabel(\"Year\")\n",
    "plt.ylabel(\"Z-score\")\n",
    "title_string_raw = \"Winter Min Temp Data for \" + str(62658)\n",
    "plt.title(title_string_raw)\n",
    "\n",
    "plt.subplot(2, 1, 2)\n",
    "plt.contourf(x_list, scales, Z)\n",
    "plt.xlabel(\"Year\")\n",
    "plt.xticks(np.arange(1900, 2016, 20))\n",
    "plt.ylabel(\"Scale\")\n",
    "plt.title(\"Harr Wavelet Coefficients, Raw Data\")\n",
    "# cbar = plt.colorbar()\n",
    "save_string = 'harr_wavelet_test_thesis.jpg'\n",
    "plt.savefig(save_string)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Plotting Wavelet Transform Coefficients"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "length of transform coefficients is: 119\n",
      "number of coefficients at lowest scale: 1380\n"
     ]
    }
   ],
   "source": [
    "ID = 272999\n",
    "N = 1380\n",
    "kernel_std = 1.25\n",
    "kernel_width = 4*kernel_std\n",
    "temps = dict_to_list(select_id(ID, StateID_objects).min_temp())\n",
    "x_list = np.linspace(1900, 2014+11.0/12, N, endpoint=True)\n",
    "smoothed_temps = gaussian_smoother(x_list, temps, kernel_std)\n",
    "\n",
    "\"\"\"\n",
    "# testing on small scale, medium scale, and large scale wavelets\n",
    "mlt_small = Morlet_Wavelet(1, 2*np.pi)\n",
    "mlt_med = Morlet_Wavelet(10, 2*np.pi)\n",
    "mlt_large = Morlet_Wavelet(25, 2*np.pi)\n",
    "\n",
    "small_coefficients = continuous_convolution(temps, mlt_small.morlet_function())\n",
    "med_coefficients = continuous_convolution(temps, mlt_med.morlet_function())\n",
    "large_coefficients = continuous_convolution(temps, mlt_large.morlet_function())\n",
    "print('-----small sampled values-----')\n",
    "print(len(mlt_small.morlet_function()))\n",
    "print(mlt_small.scale_to_year())\n",
    "print(mlt_small.sampling_points())\n",
    "print('-----med sampled values-----')\n",
    "print(len(mlt_med.morlet_function()))\n",
    "print(mlt_med.scale_to_year())\n",
    "print(mlt_med.sampling_points())\n",
    "print('------large sampled values-----')\n",
    "print(len(mlt_large.morlet_function()))\n",
    "print(mlt_large.scale_to_year())\n",
    "print(mlt_large.sampling_points())\n",
    "\n",
    "small_power = wavelet_power_spectra([small_coefficients])[0]\n",
    "med_power = wavelet_power_spectra([med_coefficients])[0]\n",
    "large_power = wavelet_power_spectra([large_coefficients])[0]\n",
    "\n",
    "N = 1380\n",
    "X = np.linspace(1900, 2014+11/12, N, endpoint=True)\n",
    "plt.plot(X, small_power, '-r', X, med_power, '-g', X, large_power, '-b')\n",
    "plt.xlabel(\"Year\")\n",
    "plt.ylabel(\"Wavelet Power\")\n",
    "plt.title(\"Wavelet Power for three scaled wavelets\")\n",
    "plt.show()\n",
    "\"\"\"\n",
    "\n",
    "transform_coefficients = continuous_transform_morlet(temps, scale_range(0.5, 30), 2*np.pi)\n",
    "transform_power = wavelet_power_spectra(transform_coefficients)\n",
    "print('length of transform coefficients is: '+str(len(transform_coefficients)))\n",
    "print('number of coefficients at lowest scale: '+str(len(transform_coefficients[0])))\n",
    "\n",
    "# smoothing data before transforming\n",
    "# NOTE: This is not a good idea, smooth wavelet coefficients after transforming instead!\n",
    "transform_coefficients_smooth = continuous_transform_morlet(smoothed_temps[1], scale_range(0.5, 30), 2*np.pi)\n",
    "transform_power_smooth = wavelet_power_spectra(transform_coefficients_smooth)\n",
    "# takes approximately 2.5 minutes per transform\n",
    "\n",
    "# renormalizing wavelet power with sample variance\n",
    "variance = sample_variance(temps)\n",
    "normalized_powers = normalized_wavelet_power_spectra(transform_power, variance)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "119\n",
      "119\n",
      "1380\n",
      "1380\n",
      "1.0470612712424183\n"
     ]
    }
   ],
   "source": [
    "print(len(transform_power))\n",
    "print(len(normalized_powers))\n",
    "\n",
    "print(len(transform_power[0]))\n",
    "print(len(normalized_powers[0]))\n",
    "\n",
    "print(variance)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# plotting wavelet power at lowest and highest scale w.r.t time\n",
    "N = 1380\n",
    "X = np.linspace(1900, 2014+11/12, N, endpoint=True)\n",
    "Y = transform_power[-1]\n",
    "Z = transform_power[0]\n",
    "plt.plot(X, Y, '-r', X, Z, '-g')\n",
    "plt.xlabel(\"Year\")\n",
    "plt.ylabel(\"Coefficient Power\")\n",
    "plt.title(\"Wavelet Power at lowest scale\")\n",
    "plt.legend(['Highest scale', 'Lowest scale'])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# plotting coefficients\n",
    "N = 1380\n",
    "X = np.linspace(1900, 2014+11/12, N, endpoint=True)\n",
    "Y = scale_range(0.5, 30)\n",
    "Z = transform_power\n",
    "Z2 = transform_power_smooth\n",
    "\n",
    "# full screen is 24,13\n",
    "plt.figure(figsize=(24,13))\n",
    "plt.subplot(2, 2, 1)\n",
    "plt.plot(X, temps)\n",
    "plt.xlim(1895, 2020)\n",
    "plt.xticks(np.arange(1900, 2016, 5))\n",
    "plt.xlabel(\"Year\")\n",
    "plt.ylabel(\"Z-score\")\n",
    "title_string_raw = \"Annual Min Temp Data for \" + str(ID)\n",
    "plt.title(title_string_raw)\n",
    "\n",
    "plt.subplot(2, 2, 3)\n",
    "plt.plot(smoothed_temps[0], smoothed_temps[1])\n",
    "plt.xlim(1895, 2020)\n",
    "plt.xticks(np.arange(1900, 2016, 5))\n",
    "plt.xlabel(\"Year\")\n",
    "plt.ylabel(\"Z-score\")\n",
    "title_string_gauss_smooth = \"Smoothed w/ Gaussian kernel, width \"+ str(kernel_width) + \" years\"\n",
    "plt.title(title_string_gauss_smooth)\n",
    "\n",
    "plt.subplot(2, 2, 2)\n",
    "plt.contourf(X, Y, Z)\n",
    "plt.xlabel(\"Year\")\n",
    "plt.ylabel(\"Scale\")\n",
    "plt.title(\"Morlet Wavelet Coefficients, Raw Data\")\n",
    "cbar = plt.colorbar()\n",
    "\n",
    "plt.subplot(2, 2, 4)\n",
    "plt.contourf(smoothed_temps[0], Y, Z2)\n",
    "plt.xlabel(\"Year\")\n",
    "plt.ylabel(\"Scale\")\n",
    "plt.title(\"Morlet Wavelet Coefficients, Smoothed Data\")\n",
    "cbar = plt.colorbar()\n",
    "\n",
    "plt.tight_layout()\n",
    "save_string = 'Morlet_Annual_Min_Temp_'+str(ID)+'_Gauss_width_'+str(int(np.floor(kernel_width)))\n",
    "#plt.savefig(save_string)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# FOR THESIS, NEED SMALLER PLOTS TO PUT ON PAGE. ONLY DOING TIME SERIES ABOVE WAVELET PLOT FOR ONE METRIC AT A TIME.\n",
    "# plotting coefficients\n",
    "N = 1380\n",
    "X = np.linspace(1900, 2014+11/12, N, endpoint=True)\n",
    "Y = scale_range(0.5, 30)\n",
    "Z = transform_power\n",
    "Z2 = transform_power_smooth\n",
    "\n",
    "# plots for thesis have 6 inch width\n",
    "plt.figure(figsize=(6, 8))\n",
    "plt.subplot(2, 1, 1)\n",
    "plt.plot(X, temps)\n",
    "plt.xlim(1895, 2020)\n",
    "plt.xticks(np.arange(1900, 2016, 20))\n",
    "plt.xlabel(\"Year\")\n",
    "plt.ylabel(\"Z-score\")\n",
    "title_string_raw = \"Annual Min Temp Data for \" + str(ID)\n",
    "plt.title(title_string_raw)\n",
    "\n",
    "plt.subplot(2, 1, 2)\n",
    "plt.contourf(X, Y, Z)\n",
    "plt.xlabel(\"Year\")\n",
    "plt.ylabel(\"Scale\")\n",
    "plt.title(\"Wavelet Coefficients, Raw Data\")\n",
    "\n",
    "plt.tight_layout()\n",
    "save_string = 'Morlet_Annual_Min_Temp_'+str(ID)+'_Gauss_width_'+str(int(np.floor(kernel_width)))+'_thesis'\n",
    "plt.savefig(save_string)\n",
    "\n",
    "# smoothing time series\n",
    "plt.figure(figsize=(6,8))\n",
    "plt.subplot(2, 1, 1)\n",
    "plt.plot(smoothed_temps[0], smoothed_temps[1])\n",
    "plt.xlim(1895, 2020)\n",
    "plt.xticks(np.arange(1900, 2016, 20))\n",
    "plt.xlabel(\"Year\")\n",
    "plt.ylabel(\"Z-score\")\n",
    "title_string_gauss_smooth = \"S(\"+ str(kernel_width) + \"yr), Min Temp\"\n",
    "plt.title(title_string_gauss_smooth)\n",
    "\n",
    "plt.subplot(2, 1, 2)\n",
    "plt.contourf(smoothed_temps[0], Y, Z2)\n",
    "plt.xlabel(\"Year\")\n",
    "plt.ylabel(\"Scale\")\n",
    "plt.title(\"Coefficients, Presmoothed Data\")\n",
    "\n",
    "plt.tight_layout()\n",
    "save_string = 'Morlet_Annual_Min_Temp_'+str(ID)+'_Gauss_width_'+str(int(np.floor(kernel_width)))+'_presmoothed_thesis'\n",
    "plt.savefig(save_string)\n",
    "\n",
    "# smoothing coefficients rather than time series\n",
    "N = 1380\n",
    "X = np.linspace(1900, 2014+11/12, N, endpoint=True)\n",
    "Y = scale_range(0.5, 30)\n",
    "Z = transform_power\n",
    "smoothed_wavelet_power = wavelet_power_smoothing(X, Z, kernel_std)\n",
    "Z2 = smoothed_wavelet_power[1]\n",
    "\n",
    "plt.figure(figsize=(6, 8))\n",
    "plt.subplot(2, 1, 1)\n",
    "plt.plot(smoothed_temps[0], smoothed_temps[1])\n",
    "plt.xlim(1895, 2020)\n",
    "plt.xticks(np.arange(1900, 2016, 20))\n",
    "plt.xlabel(\"Year\")\n",
    "plt.ylabel(\"Z-score\")\n",
    "title_string_gauss_smooth = \"S(\"+ str(kernel_width) + \"yr), Min Temp\"\n",
    "plt.title(title_string_gauss_smooth)\n",
    "\n",
    "plt.subplot(2, 1, 2)\n",
    "plt.contourf(smoothed_temps[0], Y, Z2)\n",
    "plt.xlabel(\"Year\")\n",
    "plt.ylabel(\"Scale\")\n",
    "title_string_gauss_smooth = \"S(5) Coefficients\"\n",
    "plt.title(title_string_gauss_smooth)\n",
    "\n",
    "plt.tight_layout()\n",
    "save_string = 'Morlet_Annual_Min_Temp_Smoothed_Wavelets_'+str(ID)+'_Gauss_width_'+str(int(np.floor(kernel_width)))+'_thesis'\n",
    "plt.savefig(save_string)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# smoothing coefficients rather than time series\n",
    "N = 1380\n",
    "X = np.linspace(1900, 2014+11/12, N, endpoint=True)\n",
    "Y = scale_range(0.5, 30)\n",
    "Z = transform_power\n",
    "smoothed_wavelet_power = wavelet_power_smoothing(X, Z, kernel_std)\n",
    "Z2 = smoothed_wavelet_power[1]\n",
    "\n",
    "plt.figure(figsize=(24,13))\n",
    "plt.subplot(2, 2, 1)\n",
    "plt.plot(X, temps)\n",
    "plt.xlim(1895, 2020)\n",
    "plt.xticks(np.arange(1900, 2016, 10))\n",
    "plt.xlabel(\"Year\")\n",
    "plt.ylabel(\"Z-score\")\n",
    "title_string_raw = \"Annual Min Temp Data for \" + str(ID)\n",
    "plt.title(title_string_raw)\n",
    "\n",
    "plt.subplot(2, 2, 3)\n",
    "plt.plot(smoothed_temps[0], smoothed_temps[1])\n",
    "plt.xlim(1895, 2020)\n",
    "plt.xticks(np.arange(1900, 2016, 10))\n",
    "plt.xlabel(\"Year\")\n",
    "plt.ylabel(\"Z-score\")\n",
    "title_string_gauss_smooth = \"Smoothed w/ Gaussian kernel, width \"+ str(kernel_width) + \" years\"\n",
    "plt.title(title_string_gauss_smooth)\n",
    "\n",
    "plt.subplot(2, 2, 2)\n",
    "plt.contourf(X, Y, Z)\n",
    "plt.xlabel(\"Year\")\n",
    "plt.ylabel(\"Scale\")\n",
    "plt.title(\"Morlet Wavelet Coefficients, Raw Data\")\n",
    "cbar = plt.colorbar()\n",
    "\n",
    "plt.subplot(2, 2, 4)\n",
    "plt.contourf(smoothed_temps[0], Y, Z2)\n",
    "plt.xlabel(\"Year\")\n",
    "plt.ylabel(\"Scale\")\n",
    "title_string_gauss_smooth = \"Smoothed w/ Gaussian kernel, width \"+ str(kernel_width) + \" years\"\n",
    "plt.title(title_string_gauss_smooth)\n",
    "cbar = plt.colorbar()\n",
    "\n",
    "plt.tight_layout()\n",
    "save_string = 'Morlet_Annual_Min_Temp_Smoothed_Wavelets_'+str(ID)+'_Gauss_width_'+str(int(np.floor(kernel_width)))\n",
    "#plt.savefig(save_string)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# adding COI to above code to test\n",
    "N = 1380\n",
    "X = np.linspace(1900, 2014+11/12, N, endpoint=True)\n",
    "Y = scale_range(0.5, 30)\n",
    "Y = scale_range_years(Y, 2*np.pi)\n",
    "Z = transform_power\n",
    "smoothed_wavelet_power = wavelet_power_smoothing(X, Z, kernel_std)\n",
    "Z2 = smoothed_wavelet_power[1]\n",
    "coi_data_left = coi_left(X[0], Y)\n",
    "coi_data_right = coi_right(X[-1], Y)\n",
    "\n",
    "fig = plt.figure(figsize=(24,13))\n",
    "ax1 = plt.subplot(2, 2, 1)\n",
    "ax1.plot(X, temps)\n",
    "ax1.set_xlim(1895, 2020)\n",
    "ax1.set_xticks(np.arange(1900, 2016, 5))\n",
    "ax1.set_xlabel(\"Year\")\n",
    "ax1.set_ylabel(\"Z-score\")\n",
    "title_string_raw = \"Annual Min Temp Data for \" + str(ID)\n",
    "ax1.set_title(title_string_raw)\n",
    "\n",
    "ax3 = plt.subplot(2, 2, 3)\n",
    "ax3.plot(smoothed_temps[0], smoothed_temps[1])\n",
    "ax3.set_xlim(1895, 2020)\n",
    "ax3.set_xticks(np.arange(1900, 2016, 5))\n",
    "ax3.set_xlabel(\"Year\")\n",
    "ax3.set_ylabel(\"Z-score\")\n",
    "title_string_gauss_smooth = \"Smoothed w/ Gaussian kernel, width \"+ str(kernel_width) + \" years\"\n",
    "ax3.set_title(title_string_gauss_smooth)\n",
    "\n",
    "ax2 = plt.subplot(2, 2, 2)\n",
    "ax2.contourf(X, Y, Z)\n",
    "ax2.add_patch(Polygon(coi_data_left, closed=True,fill=False,hatch='x'))\n",
    "ax2.add_patch(Polygon(coi_data_right, closed=True,fill=False,hatch='x'))\n",
    "ax2.set_xlabel(\"Year\")\n",
    "ax2.set_ylabel(\"Wavelet Period [Years]\")\n",
    "ax2.set_title(\"Morlet Wavelet Coefficients, Raw Data\")\n",
    "\n",
    "ax4 = plt.subplot(2, 2, 4)\n",
    "ax4.contourf(smoothed_wavelet_power[0], Y, Z2)\n",
    "ax4.add_patch(Polygon(coi_data_left, closed=True,fill=False,hatch='\\\\'))\n",
    "ax4.add_patch(Polygon(coi_data_right, closed=True,fill=False,hatch='/'))\n",
    "ax4.set_xlabel(\"Year\")\n",
    "ax4.set_ylabel(\"Wavelet Period [Years]\")\n",
    "title_string_gauss_smooth = \"Smoothed w/ Gaussian kernel, width \"+ str(kernel_width) + \" years\"\n",
    "ax4.set_title(title_string_gauss_smooth)\n",
    "\n",
    "fig.tight_layout()\n",
    "save_string = 'Morlet_Annual_Min_Temp_Smoothed_Wavelets_'+str(ID)+'_Gauss_width_'+str(int(np.floor(kernel_width)))\n",
    "#plt.savefig(save_string)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#DELETE THIS AFTER MAKING PLOT\n",
    "N = 1380\n",
    "X = np.linspace(1900, 2014+11/12, N, endpoint=True)\n",
    "Y = scale_range(0.5, 30)\n",
    "Y = scale_range_years(Y, 2*np.pi)\n",
    "Z = transform_power\n",
    "coi_data_left = coi_left(X[0], Y)\n",
    "coi_data_right = coi_right(X[-1], Y)\n",
    "\n",
    "fig = plt.figure(figsize=(10, 5.625))\n",
    "\n",
    "ax2 = plt.subplot(1, 1, 1)\n",
    "ax2.contourf(X, Y, Z)\n",
    "ax2.add_patch(Polygon(coi_data_left, closed=True,fill=False,hatch='x'))\n",
    "ax2.add_patch(Polygon(coi_data_right, closed=True,fill=False,hatch='x'))\n",
    "ax2.set_xlabel(\"Year\")\n",
    "ax2.set_ylabel(\"Wavelet Period [Years]\")\n",
    "ax2.set_title(\"Morlet Wavelet Coefficients, Min Temp \")\n",
    "\n",
    "fig.tight_layout()\n",
    "save_string = 'Morlet_Annual_Min_Temp_Smoothed_Wavelets_'+str(ID)+'_Gauss_width_'+str(int(np.floor(kernel_width)))+'_thesis_lowres'\n",
    "plt.savefig(save_string, dpi = 2*192)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# NOTE: THIS CODE IS NOT APPLICABLE, USES INAPPLICABLE STATISTICAL TESTING METHODS. SEE MWWAVELETS NOTES ON STAT TESTING.\n",
    "\n",
    "# testing baseline subtraction code\n",
    "N = 1380\n",
    "X = np.linspace(1900, 2014+11/12, N, endpoint=True)\n",
    "Y = scale_range(0.5, 30)\n",
    "Y = scale_range_years(Y, 2*np.pi)\n",
    "Z = normalized_powers\n",
    "smoothed_wavelet_power = wavelet_power_smoothing(X, Z, kernel_std)\n",
    "alpha = (autocorrelation(1, temps) + np.sqrt(autocorrelation(2, temps)))/2\n",
    "Z2 = base_power_subtraction(Z, Y, alpha)\n",
    "coi_data_left = coi_left(X[0], Y)\n",
    "coi_data_right = coi_right(X[-1], Y)\n",
    "\n",
    "plt.figure(figsize=(24,13))\n",
    "\n",
    "plt.subplot(2, 1, 1)\n",
    "plt.contourf(X, Y, Z)\n",
    "plt.xlabel(\"Year\")\n",
    "plt.ylabel(\"Wavelet Period [Years]\")\n",
    "plt.title(\"Morlet Wavelet Coefficients, Raw Data\")\n",
    "cbar = plt.colorbar()\n",
    "\n",
    "plt.subplot(2, 1, 2)\n",
    "plt.contourf(X, Y, Z2)\n",
    "plt.xlabel(\"Year\")\n",
    "plt.ylabel(\"Wavelet Period [Years]\")\n",
    "plt.title(\"Morlet Wavelet Coefficients, Subtracted Data\")\n",
    "plt.colorbar()\n",
    "\n",
    "fig.tight_layout()\n",
    "save_string = 'Morlet_Annual_Min_Temp_Smoothed_Wavelets_'+str(ID)+'_Gauss_width_'+str(int(np.floor(kernel_width)))\n",
    "#plt.savefig(save_string)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# this was to test making a filled shape in matplotlib\n",
    "plt.figure()\n",
    "plt.fill([1, 3, 2, 1], [1, 1, 2, 2], fill=False, hatch='\\\\')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Wavelet transform on Appalachian Sorted Data ###"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Plotting positions of StateID stations\n",
    "west_stations = Appalachian_StateID_objects[0]\n",
    "x_west_data = [i.coord()[1] for i in west_stations]\n",
    "y_west_data = [i.coord()[0] for i in west_stations]\n",
    "\n",
    "east_stations = Appalachian_StateID_objects[1]\n",
    "x_east_data = [i.coord()[1] for i in east_stations]\n",
    "y_east_data = [i.coord()[0] for i in east_stations]\n",
    "\n",
    "plt.scatter(x_west_data, y_west_data, c='red')\n",
    "plt.scatter(x_east_data, y_east_data, c='blue')\n",
    "plt.xlabel('Longitude')\n",
    "plt.ylabel('Latitude')\n",
    "plt.title('Distribution of West vs East StateIDs')\n",
    "#save_string = 'Distribution of West vs East StateIDs.jpg'\n",
    "#plt.savefig(save_string)\n",
    "plt.show()\n",
    "\n",
    "# compiling data for plotting all parameters\n",
    "# west data\n",
    "west_data = average_StateID_series(west_stations)\n",
    "west_maxtemp_data = west_data[0]\n",
    "west_mintemp_data = west_data[1]\n",
    "west_precip_data = west_data[2]\n",
    "west_nei_data = west_data[3]\n",
    "\n",
    "# east data\n",
    "east_data = average_StateID_series(east_stations)\n",
    "east_maxtemp_data = east_data[0]\n",
    "east_mintemp_data = east_data[1]\n",
    "east_precip_data = east_data[2]\n",
    "east_nei_data = east_data[3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time Elapsed: 114.32743085045877\n",
      "Time Elapsed: 113.96092951489479\n",
      "Time Elapsed: 116.67743328808751\n",
      "Time Elapsed: 114.34703879422051\n",
      "Time Elapsed: 114.46593563462602\n",
      "Time Elapsed: 112.39104911266031\n",
      "Time Elapsed: 113.78998502355091\n",
      "Time Elapsed: 134.91572732427903\n"
     ]
    }
   ],
   "source": [
    "kernel_std = 1.25\n",
    "kernel_width = 4*kernel_std\n",
    "scales = scale_range(0.5, 25)\n",
    "nei_years = scale_range_years(scales, 2*np.pi)\n",
    "x_list = np.linspace(1900, 2014+11.0/12, 1380, endpoint=True)\n",
    "\n",
    "# For West Appalachian Stations\n",
    "# max_temp\n",
    "start_time = time.perf_counter()\n",
    "west_maxtemp_transform_coeff = continuous_transform_morlet(west_maxtemp_data, scales, 2*np.pi)\n",
    "west_maxtemp_transform_power = wavelet_power_spectra(west_maxtemp_transform_coeff)\n",
    "\n",
    "west_maxtemp_smoothed_wavelet_power = wavelet_power_smoothing(x_list, west_maxtemp_transform_power, kernel_std)\n",
    "west_maxtemp_smoothed_wavelet_power_x = west_maxtemp_smoothed_wavelet_power[0]\n",
    "west_maxtemp_smoothed_wavelet_power_coeffs = west_maxtemp_smoothed_wavelet_power[1]\n",
    "end_time = time.perf_counter()\n",
    "print(\"Time Elapsed: \"+ str(end_time-start_time))\n",
    "\n",
    "# min_temp\n",
    "start_time = time.perf_counter()\n",
    "west_mintemp_transform_coeff = continuous_transform_morlet(west_mintemp_data, scales, 2*np.pi)\n",
    "west_mintemp_transform_power = wavelet_power_spectra(west_mintemp_transform_coeff)\n",
    "\n",
    "west_mintemp_smoothed_wavelet_power = wavelet_power_smoothing(x_list, west_mintemp_transform_power, kernel_std)\n",
    "west_mintemp_smoothed_wavelet_power_x = west_mintemp_smoothed_wavelet_power[0]\n",
    "west_mintemp_smoothed_wavelet_power_coeffs = west_mintemp_smoothed_wavelet_power[1]\n",
    "end_time = time.perf_counter()\n",
    "print(\"Time Elapsed: \"+ str(end_time-start_time))\n",
    "\n",
    "#precip\n",
    "start_time = time.perf_counter()\n",
    "west_precip_transform_coeff = continuous_transform_morlet(west_precip_data, scales, 2*np.pi)\n",
    "west_precip_transform_power = wavelet_power_spectra(west_precip_transform_coeff)\n",
    "\n",
    "west_precip_smoothed_wavelet_power = wavelet_power_smoothing(x_list, west_precip_transform_power, kernel_std)\n",
    "west_precip_smoothed_wavelet_power_x = west_precip_smoothed_wavelet_power[0]\n",
    "west_precip_smoothed_wavelet_power_coeffs = west_precip_smoothed_wavelet_power[1]\n",
    "end_time = time.perf_counter()\n",
    "print(\"Time Elapsed: \"+ str(end_time-start_time))\n",
    "\n",
    "#nei\n",
    "start_time = time.perf_counter()\n",
    "west_nei_transform_coeff = continuous_transform_morlet(west_nei_data, scales, 2*np.pi)\n",
    "west_nei_transform_power = wavelet_power_spectra(west_nei_transform_coeff)\n",
    "\n",
    "west_nei_smoothed_wavelet_power = wavelet_power_smoothing(x_list, west_nei_transform_power, kernel_std)\n",
    "west_nei_smoothed_wavelet_power_x = west_nei_smoothed_wavelet_power[0]\n",
    "west_nei_smoothed_wavelet_power_coeffs = west_nei_smoothed_wavelet_power[1]\n",
    "end_time = time.perf_counter()\n",
    "print(\"Time Elapsed: \"+ str(end_time-start_time))\n",
    "\n",
    "# For East Appalacian Stations\n",
    "# max_temp\n",
    "start_time = time.perf_counter()\n",
    "east_maxtemp_transform_coeff = continuous_transform_morlet(east_maxtemp_data, scales, 2*np.pi)\n",
    "east_maxtemp_transform_power = wavelet_power_spectra(east_maxtemp_transform_coeff)\n",
    "\n",
    "east_maxtemp_smoothed_wavelet_power = wavelet_power_smoothing(x_list, east_maxtemp_transform_power, kernel_std)\n",
    "east_maxtemp_smoothed_wavelet_power_x = east_maxtemp_smoothed_wavelet_power[0]\n",
    "east_maxtemp_smoothed_wavelet_power_coeffs = east_maxtemp_smoothed_wavelet_power[1]\n",
    "end_time = time.perf_counter()\n",
    "print(\"Time Elapsed: \"+ str(end_time-start_time))\n",
    "\n",
    "# min_temp\n",
    "start_time = time.perf_counter()\n",
    "east_mintemp_transform_coeff = continuous_transform_morlet(east_mintemp_data, scales, 2*np.pi)\n",
    "east_mintemp_transform_power = wavelet_power_spectra(east_mintemp_transform_coeff)\n",
    "\n",
    "east_mintemp_smoothed_wavelet_power = wavelet_power_smoothing(x_list, east_mintemp_transform_power, kernel_std)\n",
    "east_mintemp_smoothed_wavelet_power_x = east_mintemp_smoothed_wavelet_power[0]\n",
    "east_mintemp_smoothed_wavelet_power_coeffs = east_mintemp_smoothed_wavelet_power[1]\n",
    "end_time = time.perf_counter()\n",
    "print(\"Time Elapsed: \"+ str(end_time-start_time))\n",
    "\n",
    "# precip\n",
    "start_time = time.perf_counter()\n",
    "east_precip_transform_coeff = continuous_transform_morlet(east_precip_data, scales, 2*np.pi)\n",
    "east_precip_transform_power = wavelet_power_spectra(east_precip_transform_coeff)\n",
    "\n",
    "east_precip_smoothed_wavelet_power = wavelet_power_smoothing(x_list, east_precip_transform_power, kernel_std)\n",
    "east_precip_smoothed_wavelet_power_x = east_precip_smoothed_wavelet_power[0]\n",
    "east_precip_smoothed_wavelet_power_coeffs = east_precip_smoothed_wavelet_power[1]\n",
    "end_time = time.perf_counter()\n",
    "print(\"Time Elapsed: \"+ str(end_time-start_time))\n",
    "\n",
    "# nei\n",
    "start_time = time.perf_counter()\n",
    "east_nei_transform_coeff = continuous_transform_morlet(east_nei_data, scales, 2*np.pi)\n",
    "east_nei_transform_power = wavelet_power_spectra(east_nei_transform_coeff)\n",
    "\n",
    "east_nei_smoothed_wavelet_power = wavelet_power_smoothing(x_list, east_nei_transform_power, kernel_std)\n",
    "east_nei_smoothed_wavelet_power_x = east_nei_smoothed_wavelet_power[0]\n",
    "east_nei_smoothed_wavelet_power_coeffs = east_nei_smoothed_wavelet_power[1]\n",
    "end_time = time.perf_counter()\n",
    "print(\"Time Elapsed: \"+ str(end_time-start_time))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Plotting time series from above\n",
    "N = 1380\n",
    "X = np.linspace(1900, 2014+11/12, N, endpoint=True)\n",
    "my_dpi = float(96)\n",
    "\n",
    "kernel_std = 1.25\n",
    "# maxtemp_data\n",
    "west_maxtemp_data_smooth = gaussian_smoother(X, west_maxtemp_data, kernel_std)\n",
    "east_maxtemp_data_smooth = gaussian_smoother(X, east_maxtemp_data, kernel_std)\n",
    "fig = plt.figure(figsize=(50, 22.5))\n",
    "plt.subplot(2,1,1)\n",
    "plt.plot(west_maxtemp_data_smooth[0], west_maxtemp_data_smooth[1])\n",
    "plt.xlim(1895, 2020)\n",
    "plt.xticks(np.arange(1900, 2016, 10))\n",
    "plt.xlabel(\"Year\")\n",
    "plt.ylabel(\"Z-score\")\n",
    "plt.title('Averaged Monthly Maximum Temperature, West of Appalacians, Smoothed w/ 5 Year Gaussian')\n",
    "\n",
    "plt.subplot(2,1,2)\n",
    "plt.plot(east_maxtemp_data_smooth[0], east_maxtemp_data_smooth[1])\n",
    "plt.xlim(1895, 2020)\n",
    "plt.xticks(np.arange(1900, 2016, 10))\n",
    "plt.xlabel(\"Year\")\n",
    "plt.ylabel(\"Z-score\")\n",
    "plt.title('Averaged Monthly Maximum Temperature, East of Appalacians, Smoothed w/ 5 Year Gaussian')\n",
    "\n",
    "plt.tight_layout()\n",
    "\n",
    "save_string = 'West vs East of Appalachian Mountain Max Temp_presentation_timeseries.jpg'\n",
    "plt.savefig(save_string, dpi=my_dpi)\n",
    "plt.gcf().clear()\n",
    "\n",
    "west_mintemp_data_smooth = gaussian_smoother(X, west_mintemp_data, kernel_std)\n",
    "east_mintemp_data_smooth = gaussian_smoother(X, east_mintemp_data, kernel_std)\n",
    "fig = plt.figure(figsize=(25, 11.25))\n",
    "plt.subplot(2,1,1)\n",
    "plt.plot(west_mintemp_data_smooth[0], west_mintemp_data_smooth[1])\n",
    "plt.xlim(1895, 2020)\n",
    "plt.xticks(np.arange(1900, 2016, 10))\n",
    "plt.xlabel(\"Year\")\n",
    "plt.ylabel(\"Z-score\")\n",
    "plt.title('Averaged Monthly Minimum Temperature, West of Appalacians, Smoothed w/ 5 Year Gaussian')\n",
    "\n",
    "plt.subplot(2,1,2)\n",
    "plt.plot(east_mintemp_data_smooth[0], east_mintemp_data_smooth[1])\n",
    "plt.xlim(1895, 2020)\n",
    "plt.xticks(np.arange(1900, 2016, 10))\n",
    "plt.xlabel(\"Year\")\n",
    "plt.ylabel(\"Z-score\")\n",
    "plt.title('Averaged Monthly Minimum Temperature, East of Appalacians, Smoothed w/ 5 Year Gaussian')\n",
    "\n",
    "plt.tight_layout()\n",
    "\n",
    "save_string = 'West vs East of Appalachian Mountain Min Temp_presentation_timeseries.jpg'\n",
    "plt.savefig(save_string, dpi=2*my_dpi)\n",
    "plt.gcf().clear()\n",
    "\n",
    "west_precip_data_smooth = gaussian_smoother(X, west_precip_data, kernel_std)\n",
    "east_precip_data_smooth = gaussian_smoother(X, east_precip_data, kernel_std)\n",
    "fig = plt.figure(figsize=(25, 11.25))\n",
    "plt.subplot(2,1,1)\n",
    "plt.plot(west_precip_data_smooth[0], west_precip_data_smooth[1])\n",
    "plt.xlim(1895, 2020)\n",
    "plt.xticks(np.arange(1900, 2016, 10))\n",
    "plt.xlabel(\"Year\")\n",
    "plt.ylabel(\"Z-score\")\n",
    "plt.title('Averaged Monthly Precipitation, West of Appalacians, Smoothed w/ 5 Year Gaussian')\n",
    "\n",
    "plt.subplot(2,1,2)\n",
    "plt.plot(east_precip_data_smooth[0], east_precip_data_smooth[1])\n",
    "plt.xlim(1895, 2020)\n",
    "plt.xticks(np.arange(1900, 2016, 10))\n",
    "plt.xlabel(\"Year\")\n",
    "plt.ylabel(\"Z-score\")\n",
    "plt.title('Averaged Monthly Precipitation, East of Appalacians, Smoothed w/ 5 Year Gaussian')\n",
    "\n",
    "plt.tight_layout()\n",
    "\n",
    "save_string = 'West vs East of Appalachian Mountain Precip_presentation_timeseries.jpg'\n",
    "plt.savefig(save_string, dpi=2*my_dpi)\n",
    "plt.gcf().clear()\n",
    "\n",
    "west_nei_data_smooth = gaussian_smoother(X, west_nei_data, kernel_std)\n",
    "east_nei_data_smooth = gaussian_smoother(X, east_nei_data, kernel_std)\n",
    "fig = plt.figure(figsize=(25, 11.25))\n",
    "plt.subplot(2,1,1)\n",
    "plt.plot(west_nei_data_smooth[0], west_nei_data_smooth[1])\n",
    "plt.xlim(1895, 2020)\n",
    "plt.xticks(np.arange(1900, 2016, 10))\n",
    "plt.xlabel(\"Year\")\n",
    "plt.ylabel(\"Z-score\")\n",
    "plt.title('Averaged Monthly NEI, West of Appalacians, Smoothed w/ 5 Year Gaussian')\n",
    "\n",
    "plt.subplot(2,1,2)\n",
    "plt.plot(east_nei_data_smooth[0], east_nei_data_smooth[1])\n",
    "plt.xlim(1895, 2020)\n",
    "plt.xticks(np.arange(1900, 2016, 10))\n",
    "plt.xlabel(\"Year\")\n",
    "plt.ylabel(\"Z-score\")\n",
    "plt.title('Averaged Monthly NEI, East of Appalacians, Smoothed w/ 5 Year Gaussian')\n",
    "\n",
    "plt.tight_layout()\n",
    "\n",
    "save_string = 'West vs East of Appalachian Mountain NEI_presentation_timeseries.jpg'\n",
    "plt.savefig(save_string, dpi=2*my_dpi)\n",
    "plt.gcf().clear()\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Anaconda3\\lib\\site-packages\\matplotlib\\pyplot.py:516: RuntimeWarning: More than 20 figures have been opened. Figures created through the pyplot interface (`matplotlib.pyplot.figure`) are retained until explicitly closed and may consume too much memory. (To control this warning, see the rcParam `figure.max_open_warning`).\n",
      "  max_open_warning, RuntimeWarning)\n"
     ]
    }
   ],
   "source": [
    "# Plotting Coefficients from above\n",
    "# doing pairs of plots, one for each parameter, comparing between West/East stations (gives 4 plots)\n",
    "my_dpi = float(96)\n",
    "# maxtemp\n",
    "plt.gcf().clear()\n",
    "#FOR THESIS, 6,8, for full screen, 24,13\n",
    "#FOR PRESENTATION, 5760/dpi, 2160/dpi (my_dpi=96) (50 by 22.5in)\n",
    "# also for presentation, want a \n",
    "fig = plt.figure(figsize=(25, 11.25))\n",
    "plt.subplot(2,1,1)\n",
    "plt.contourf(west_maxtemp_smoothed_wavelet_power_x, nei_years, west_maxtemp_smoothed_wavelet_power_coeffs)\n",
    "plt.xlabel(\"Year\")\n",
    "plt.ylabel(\"Scale [Years]\")\n",
    "plt.title(\"Morlet Wavelet Coefficients for Max Temp, West of Appalachians\")\n",
    "#plt.title(\"Max Temp, West\") # for thesis\n",
    "cbar = plt.colorbar()\n",
    "\n",
    "plt.subplot(2,1,2)\n",
    "plt.contourf(east_maxtemp_smoothed_wavelet_power_x, nei_years, east_maxtemp_smoothed_wavelet_power_coeffs)\n",
    "plt.xlabel(\"Year\")\n",
    "plt.ylabel(\"Scale [Years]\")\n",
    "plt.title(\"Morlet Wavelet Coefficients for Max Temp, East of Appalachians\")\n",
    "#plt.title(\"Max Temp, East\") # for thesis\n",
    "cbar = plt.colorbar()\n",
    "fig.tight_layout()\n",
    "\n",
    "save_string = 'West vs East of Appalachian Mountain Max Temp_presentation.jpg'\n",
    "plt.savefig(save_string, dpi=2*my_dpi)\n",
    "plt.gcf().clear()\n",
    "\n",
    "# mintemp\n",
    "fig = plt.figure(figsize=(25, 11.25))\n",
    "plt.subplot(2,1,1)\n",
    "plt.contourf(west_mintemp_smoothed_wavelet_power_x, nei_years, west_mintemp_smoothed_wavelet_power_coeffs)\n",
    "plt.xlabel(\"Year\")\n",
    "plt.ylabel(\"Scale [Years]\")\n",
    "plt.title(\"Morlet Wavelet Coefficients for Min Temp, West of Appalacians\")\n",
    "#plt.title(\"Min Temp, West\") # thesis\n",
    "cbar = plt.colorbar()\n",
    "\n",
    "plt.subplot(2,1,2)\n",
    "plt.contourf(east_mintemp_smoothed_wavelet_power_x, nei_years, east_mintemp_smoothed_wavelet_power_coeffs)\n",
    "plt.xlabel(\"Year\")\n",
    "plt.ylabel(\"Scale [Years]\")\n",
    "plt.title(\"Morlet Wavelet Coefficients for Min Temp, East of Appalachians\")\n",
    "#plt.title(\"Min Temp, East\") # thesis\n",
    "cbar = plt.colorbar()\n",
    "\n",
    "fig.tight_layout()\n",
    "\n",
    "save_string = 'West vs East of Appalachian Mountain Min Temp_presentation.jpg'\n",
    "plt.savefig(save_string, dpi=2*my_dpi)\n",
    "plt.gcf().clear()\n",
    "\n",
    "# precip\n",
    "fig = plt.figure(figsize=(25, 11.25))\n",
    "plt.subplot(2,1,1)\n",
    "plt.contourf(west_precip_smoothed_wavelet_power_x, nei_years, west_precip_smoothed_wavelet_power_coeffs)\n",
    "plt.xlabel(\"Year\")\n",
    "plt.ylabel(\"Scale [Years]\")\n",
    "plt.title(\"Morlet Wavelet Coefficients for Precip, West of Appalachians\")\n",
    "#plt.title(\"Precip, West\")\n",
    "cbar = plt.colorbar()\n",
    "\n",
    "plt.subplot(2,1,2)\n",
    "plt.contourf(east_precip_smoothed_wavelet_power_x, nei_years, east_precip_smoothed_wavelet_power_coeffs)\n",
    "plt.xlabel(\"Year\")\n",
    "plt.ylabel(\"Scale [Years]\")\n",
    "plt.title(\"Morlet Wavelet Coefficients for Precip, East of Appalachians\")\n",
    "#plt.title(\"Precip, East\")\n",
    "cbar = plt.colorbar()\n",
    "\n",
    "fig.tight_layout()\n",
    "\n",
    "save_string = 'West vs East of Appalachian Mountain Precip_presentation.jpg'\n",
    "plt.savefig(save_string, dpi=2*my_dpi)\n",
    "plt.gcf().clear()\n",
    "\n",
    "# nei\n",
    "fig = plt.figure(figsize=(25, 11.25))\n",
    "plt.subplot(2,1,1)\n",
    "plt.contourf(west_nei_smoothed_wavelet_power_x, nei_years, west_nei_smoothed_wavelet_power_coeffs)\n",
    "plt.xlabel(\"Year\")\n",
    "plt.ylabel(\"Scale [Years]\")\n",
    "plt.title(\"Morlet Wavelet Coefficients for NEI, West of Appalachians\")\n",
    "#plt.title(\"NEI, West\")\n",
    "cbar = plt.colorbar()\n",
    "\n",
    "plt.subplot(2,1,2)\n",
    "plt.contourf(east_nei_smoothed_wavelet_power_x, nei_years, east_nei_smoothed_wavelet_power_coeffs)\n",
    "plt.xlabel(\"Year\")\n",
    "plt.ylabel(\"Scale [Years]\")\n",
    "plt.title(\"Morlet Wavelet Coefficients for NEI, East of Appalachians\")\n",
    "#plt.title(\"NEI, East\")\n",
    "cbar = plt.colorbar()\n",
    "\n",
    "fig.tight_layout()\n",
    "\n",
    "save_string = 'West vs East of Appalachian Mountain NEI_presentation.jpg'\n",
    "plt.savefig(save_string, dpi=2*my_dpi)\n",
    "plt.gcf().clear()\n",
    "plt.show()\n",
    "#could do a 4-part-plot where stations w/ coordinates are plotted on the right, corresponding wavelets on left\n",
    "# also a 2 row by 3 column huge plot w/ coordinates on far right, averaged indices in middle, wavelets on the left"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Testing Wavelet Transform on Noisy Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "x_list = np.linspace(0, 100, 1000)\n",
    "y_list_noise = red_noise_generator(0.345084339548, 2, 1000)\n",
    "y_list_values = line_generator(-3, 0.06, x_list)\n",
    "noisy_data = noisy_line_generator(x_list, y_list_values, y_list_noise)\n",
    "\n",
    "noisy_scales = scale_range(0.5, 30)\n",
    "noisy_coefficients = continuous_transform_morlet(noisy_data[1], noisy_scales, 2*np.pi)\n",
    "noisy_transform_power = wavelet_power_spectra(noisy_coefficients)\n",
    "\n",
    "noisy_flat_coefficients = continuous_transform_morlet(y_list_noise, noisy_scales, 2*np.pi)\n",
    "noisy_flat_transform_power = wavelet_power_spectra(noisy_flat_coefficients)\n",
    "# takes about 6.5 minutes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize=(24,13))\n",
    "plt.subplot(2,2,1)\n",
    "plt.plot(noisy_data[0], noisy_data[1])\n",
    "plt.xlim(0, 100)\n",
    "plt.xticks(np.arange(0, 100, 5))\n",
    "plt.xlabel(\"Sequence Index\")\n",
    "plt.ylabel(\"Y Value\")\n",
    "plt.title(\"Linear trend w/ Noisy Data\")\n",
    "\n",
    "plt.subplot(2,2,3)\n",
    "plt.plot(noisy_data[0], y_list_noise)\n",
    "plt.xlim(0, 100)\n",
    "plt.xticks(np.arange(0, 100, 5))\n",
    "plt.xlabel(\"Sequence Index\")\n",
    "plt.ylabel(\"Y Value\")\n",
    "plt.title(\"No trend w/ Noisy Data\")\n",
    "\n",
    "plt.subplot(2,2,2)\n",
    "plt.contourf(noisy_data[0], noisy_scales, noisy_transform_power)\n",
    "plt.xlabel(\"Year\")\n",
    "plt.ylabel(\"Scale\")\n",
    "plt.title(\"Morlet Wavelet Coefficients, Noisy Data\")\n",
    "cbar = plt.colorbar()\n",
    "\n",
    "plt.subplot(2,2,4)\n",
    "plt.contourf(noisy_data[0], noisy_scales, noisy_flat_transform_power)\n",
    "plt.xlabel(\"Year\")\n",
    "plt.ylabel(\"Scale\")\n",
    "plt.title(\"Morlet Wavelet Coefficients, Noisy Data w/o Trend\")\n",
    "cbar = plt.colorbar()\n",
    "\n",
    "plt.tight_layout()\n",
    "save_string = 'Noisy Data r = 0.345084339548 Test.jpg'\n",
    "#plt.savefig(save_string)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# FOR THESIS\n",
    "plt.figure(figsize=(6,8))\n",
    "plt.subplot(2,1,1)\n",
    "plt.plot(noisy_data[0], noisy_data[1])\n",
    "plt.xlim(0, 100)\n",
    "plt.xticks(np.arange(0, 100, 5))\n",
    "plt.xlabel(\"Sequence Index\")\n",
    "plt.ylabel(\"Y Value\")\n",
    "plt.title(\"Linear trend Noisy Data\")\n",
    "\n",
    "plt.subplot(2,1,2)\n",
    "plt.contourf(noisy_data[0], noisy_scales, noisy_transform_power)\n",
    "plt.xlabel(\"Year\")\n",
    "plt.ylabel(\"Scale\")\n",
    "plt.title(\"Wavelet Coefficients, Noisy\")\n",
    "cbar = plt.colorbar()\n",
    "\n",
    "plt.tight_layout()\n",
    "save_string = 'Noisy Data r = 0.345084339548 Test_trend_thesis.jpg'\n",
    "plt.savefig(save_string)\n",
    "\n",
    "plt.figure(figsize=(6,8))\n",
    "plt.subplot(2,1,1)\n",
    "plt.plot(noisy_data[0], y_list_noise)\n",
    "plt.xlim(0, 100)\n",
    "plt.xticks(np.arange(0, 100, 5))\n",
    "plt.xlabel(\"Sequence Index\")\n",
    "plt.ylabel(\"Y Value\")\n",
    "plt.title(\"No trend Noisy Data\")\n",
    "\n",
    "plt.subplot(2,1,2)\n",
    "plt.contourf(noisy_data[0], noisy_scales, noisy_flat_transform_power)\n",
    "plt.xlabel(\"Year\")\n",
    "plt.ylabel(\"Scale\")\n",
    "plt.title(\"Wavelet Coefficients, Noisy w/o Trend\")\n",
    "cbar = plt.colorbar()\n",
    "\n",
    "plt.tight_layout()\n",
    "save_string = 'Noisy Data r = 0.345084339548 Test_no_trend_thesis.jpg'\n",
    "plt.savefig(save_string)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Wavelet Transforms on Sines w/ Trends"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3462.080049026702"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# transforming the data with timing\n",
    "time.clock()\n",
    "length = 100\n",
    "x_list = np.linspace(0, length, 10*length)\n",
    "freq = 2*np.pi/10\n",
    "slope = 0.03\n",
    "y_list_sine = list(np.sin(freq*x_list))\n",
    "y_list_trend = line_generator(-1.5, slope, x_list)\n",
    "y_list_sinetrend = []\n",
    "for i in range(len(y_list_sine)):\n",
    "    y_list_sinetrend.append(y_list_sine[i]+y_list_trend[i])\n",
    "\n",
    "sine_scales = scale_range(0.5, 50)\n",
    "sine_years = scale_range_years(sine_scales, 2*np.pi)\n",
    "sine_coefficients = continuous_transform_morlet(y_list_sine, sine_scales, 2*np.pi)\n",
    "sine_transform_power = wavelet_power_spectra(sine_coefficients)\n",
    "\n",
    "sinetrend_coefficients = continuous_transform_morlet(y_list_sinetrend, sine_scales, 2*np.pi)\n",
    "sinetrend_transform_power = wavelet_power_spectra(sinetrend_coefficients)\n",
    "time.clock()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# plotting the coefficients\n",
    "plt.figure(figsize=(24,13))\n",
    "plt.subplot(2,2,1)\n",
    "plt.plot(x_list, y_list_sine)\n",
    "plt.xlim(0, length)\n",
    "plt.xticks(np.arange(0, length, 5))\n",
    "plt.xlabel(\"Sequence Index\")\n",
    "plt.ylabel(\"Y Value\")\n",
    "plt.title(\"Sine w/o Trend, frequency: \"+str(freq))\n",
    "\n",
    "plt.subplot(2,2,3)\n",
    "plt.plot(x_list, y_list_sinetrend)\n",
    "plt.xlim(0, length)\n",
    "plt.xticks(np.arange(0, length, 5))\n",
    "plt.xlabel(\"Sequence Index\")\n",
    "plt.ylabel(\"Y Value\")\n",
    "plt.title(\"Sine w/ Trend, slope: \"+str(slope))\n",
    "\n",
    "plt.subplot(2,2,2)\n",
    "plt.contourf(x_list, sine_years, sine_transform_power)\n",
    "plt.xticks(np.arange(0, length, 5))\n",
    "plt.xlabel(\"Index\")\n",
    "plt.ylabel(\"Period [Years]\")\n",
    "plt.title(\"Morlet Wavelet Coefficients, Sine\")\n",
    "cbar = plt.colorbar()\n",
    "\n",
    "plt.subplot(2,2,4)\n",
    "plt.contourf(x_list, sine_years, sinetrend_transform_power)\n",
    "plt.xticks(np.arange(0, length, 5))\n",
    "plt.xlabel(\"Index\")\n",
    "plt.ylabel(\"Period [Years]\")\n",
    "plt.title(\"Morlet Wavelet Coefficients, Sine w/ Trend\")\n",
    "cbar = plt.colorbar()\n",
    "\n",
    "plt.tight_layout()\n",
    "save_string = 'Sine '+str(freq)+' slope '+str(slope)+' length '+str(length)+'.jpg'\n",
    "#plt.savefig(save_string)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# FOR THESIS\n",
    "plt.figure(figsize=(6,8))\n",
    "plt.subplot(2,1,1)\n",
    "plt.plot(x_list, y_list_sine)\n",
    "plt.xlim(0, length)\n",
    "plt.xticks(np.arange(0, length, 10))\n",
    "plt.xlabel(\"Sequence Index\")\n",
    "plt.ylabel(\"Y Value\")\n",
    "plt.title(\"Sine w/o Trend, freq: \"+str(freq))\n",
    "\n",
    "plt.subplot(2,1,2)\n",
    "plt.contourf(x_list, sine_years, sine_transform_power)\n",
    "plt.xticks(np.arange(0, length, 10))\n",
    "plt.xlabel(\"Index\")\n",
    "plt.ylabel(\"Period [Years]\")\n",
    "plt.title(\"Wavelet Coefficients, Sine\")\n",
    "cbar = plt.colorbar()\n",
    "\n",
    "plt.tight_layout()\n",
    "save_string = 'Sine '+str(freq)+' slope '+str(slope)+' length '+str(length)+'_no_trend_thesis.jpg'\n",
    "plt.savefig(save_string)\n",
    "\n",
    "plt.figure(figsize=(6,8))\n",
    "plt.subplot(2,1,1)\n",
    "plt.plot(x_list, y_list_sinetrend)\n",
    "plt.xlim(0, length)\n",
    "plt.xticks(np.arange(0, length, 10))\n",
    "plt.xlabel(\"Sequence Index\")\n",
    "plt.ylabel(\"Y Value\")\n",
    "plt.title(\"Sine w/ Trend, slope: \"+str(slope))\n",
    "\n",
    "plt.subplot(2,1,2)\n",
    "plt.contourf(x_list, sine_years, sinetrend_transform_power)\n",
    "plt.xticks(np.arange(0, length, 10))\n",
    "plt.xlabel(\"Index\")\n",
    "plt.ylabel(\"Period [Years]\")\n",
    "plt.title(\"Wavelet Coefficients, Sine w/ Trend\")\n",
    "cbar = plt.colorbar()\n",
    "\n",
    "plt.tight_layout()\n",
    "save_string = 'Sine '+str(freq)+' slope '+str(slope)+' length '+str(length)+'_trend_thesis.jpg'\n",
    "plt.savefig(save_string)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Wavelet Transforms on NEI Averaged Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time Elapsed: 76.19479046463948\n"
     ]
    }
   ],
   "source": [
    "# names of data sets for all Northeast averaged data:\n",
    "# avg_nei, avg_max_temps, avg_min_temps, avg_precips\n",
    "start_time = time.perf_counter()\n",
    "data = avg_nei\n",
    "kernel_std = 1.25\n",
    "kernel_width = 4*kernel_std\n",
    "scales = scale_range(0.5, 25)\n",
    "nei_years = scale_range_years(scales, 2*np.pi)\n",
    "x_list = np.linspace(1900, 2014+11.0/12, 1380, endpoint=True)\n",
    "\n",
    "transform_coeff = continuous_transform_morlet(data, scales, 2*np.pi)\n",
    "transform_power = wavelet_power_spectra(transform_coeff)\n",
    "\n",
    "smoothed_wavelet_power = wavelet_power_smoothing(x_list, transform_power, kernel_std)\n",
    "smoothed_wavelet_power_x = smoothed_wavelet_power[0]\n",
    "smoothed_wavelet_power_coeffs = smoothed_wavelet_power[1]\n",
    "end_time = time.perf_counter()\n",
    "print(\"Time Elapsed: \"+ str(end_time-start_time))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# plotting smoothed data\n",
    "smoothed_data = gaussian_smoother(x_list, data, kernel_std)\n",
    "\n",
    "fig = plt.figure(figsize=(18,5))\n",
    "plt.plot(smoothed_data[0], smoothed_data[1])\n",
    "plt.xlim(1900, 2016)\n",
    "plt.xticks(np.arange(1900, 2016, 5))\n",
    "plt.xlabel(\"Year\")\n",
    "plt.ylabel(\"Z-score\")\n",
    "title_string_gauss_smooth = \"Smoothed w/ Gaussian kernel, width \"+ str(kernel_width) + \" years\"\n",
    "plt.title(title_string_gauss_smooth)\n",
    "save_string = \"max_temp_data_smoothed_all_stations\"\n",
    "#plt.savefig(save_string)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# plotting transform\n",
    "coi_data_left = coi_left(x_list[0], nei_years)\n",
    "coi_data_right = coi_right(x_list[-1], nei_years)\n",
    "\n",
    "#size is usually 24,13\n",
    "fig = plt.figure(figsize=(18,10))\n",
    "ax1 = plt.subplot(2, 1, 1)\n",
    "ax1.plot(x_list, data)\n",
    "ax1.set_xlim(1900, 2016)\n",
    "ax1.set_xticks(np.arange(1900, 2016, 5))\n",
    "ax1.set_xlabel(\"Year\")\n",
    "ax1.set_ylabel(\"Z-score\")\n",
    "title_string_raw = \"Average Max Temp Data for All StateIDs\"\n",
    "ax1.set_title(title_string_raw)\n",
    "\n",
    "ax2 = plt.subplot(2, 1, 2)\n",
    "ax2.contourf(x_list, nei_years, transform_power)\n",
    "ax2.add_patch(Polygon(coi_data_left, closed=True,fill=False,hatch='\\\\'))\n",
    "ax2.add_patch(Polygon(coi_data_right, closed=True,fill=False,hatch='/'))\n",
    "ax2.set_xlabel(\"Year\")\n",
    "ax2.set_ylabel(\"Wavelet Period [Years]\")\n",
    "ax2.set_title(\"Morlet Wavelet Coefficients, Avg Max Temp Data\")\n",
    "save_string = 'avg_precip_data_with_wavelet_coefficients_all_stations'\n",
    "#plt.savefig(save_string)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# FOR THESIS, PLOTTING SMOOTHED DATA WITH TRANSFORMED DATA\n",
    "coi_data_left = coi_left(x_list[0], nei_years)\n",
    "coi_data_right = coi_right(x_list[-1], nei_years)\n",
    "\n",
    "smoothed_data = gaussian_smoother(x_list, data, kernel_std)\n",
    "\n",
    "#size is usually 24,13\n",
    "fig = plt.figure(figsize=(6,8))\n",
    "ax1 = plt.subplot(2, 1, 1)\n",
    "ax1.plot(smoothed_data[0], smoothed_data[1])\n",
    "ax1.set_xlim(1900, 2016)\n",
    "ax1.set_xticks(np.arange(1900, 2016, 20))\n",
    "ax1.set_ylabel(\"Z-score\")\n",
    "title_string_raw = \"Smooth(5yr) NEI, All StateIDs\"\n",
    "ax1.set_title(title_string_raw)\n",
    "\n",
    "ax2 = plt.subplot(2, 1, 2)\n",
    "ax2.contourf(x_list, nei_years, transform_power)\n",
    "ax2.add_patch(Polygon(coi_data_left, closed=True,fill=False,hatch='\\\\'))\n",
    "ax2.add_patch(Polygon(coi_data_right, closed=True,fill=False,hatch='/'))\n",
    "ax2.set_xlabel(\"Year\")\n",
    "ax2.set_ylabel(\"Wavelet Period [Years]\")\n",
    "ax2.set_title(\"Wavelet Coefficients, NEI\")\n",
    "save_string = 'avg_nei_data_with_wavelet_coefficients_all_stations_thesis'\n",
    "plt.savefig(save_string)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Applying Harr Wavelet to Various Data Sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time Elapsed: 0.3879398009519264\n"
     ]
    }
   ],
   "source": [
    "# running Harr wavelet on random data\n",
    "start_time = time.perf_counter()\n",
    "\n",
    "x_list = np.linspace(0, 116, 460)\n",
    "r = 0.35\n",
    "std_dev = 1\n",
    "y_list_noise = red_noise_generator(r, std_dev, 1000)\n",
    "y_list_values = line_generator(0, 0.00, x_list)\n",
    "noisy_data = noisy_line_generator(x_list, y_list_values, y_list_noise)\n",
    "\n",
    "#station = select_id(62658, StateID_objects)\n",
    "#min_winter_temps_list = dict_to_list(station.max_temp_winter())\n",
    "#N = len(min_winter_temps_list)\n",
    "#x_list = np.linspace(1900, 2014+0.75, N, endpoint=True)\n",
    "scales = harr_scale_range((1.0/6.0), 10)\n",
    "transform_coefficients = continuous_transform_harr(noisy_data[1], scales)\n",
    "\n",
    "end_time = time.perf_counter()\n",
    "print(\"Time Elapsed: \"+ str(end_time-start_time))\n",
    "\n",
    "Z = transform_coefficients\n",
    "\n",
    "# usually 24,13\n",
    "plt.figure(figsize=(6,8))\n",
    "plt.subplot(2, 1, 1)\n",
    "plt.plot(x_list, noisy_data[1])\n",
    "#plt.xlabel(\"Year\")\n",
    "plt.ylabel(\"Z-score\")\n",
    "title_string_raw = \"Red Noise w/ r =\" + str(r) + \" and std_dev = \" + str(std_dev)\n",
    "plt.title(title_string_raw)\n",
    "\n",
    "plt.subplot(2, 1, 2)\n",
    "plt.contourf(x_list, scales, Z)\n",
    "plt.xlabel(\"Year\")\n",
    "plt.ylabel(\"Scale\")\n",
    "plt.title(\"Harr Wavelet Coefficients, Raw Data\")\n",
    "#cbar = plt.colorbar()\n",
    "save_string = 'harr_wavelet_noise_thesis'\n",
    "plt.savefig(save_string)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time Elapsed: 0.39255864825645403\n"
     ]
    }
   ],
   "source": [
    "# Harr wavelet on linear baseline data\n",
    "start_time = time.perf_counter()\n",
    "\n",
    "x_list = np.linspace(0, 116, 460)\n",
    "r = 0.35\n",
    "std_dev = 1\n",
    "y_list_noise = red_noise_generator(r, std_dev, 1000)\n",
    "y_list_values = line_generator(-1, 2.0/116.0, x_list)\n",
    "noisy_data = noisy_line_generator(x_list, y_list_values, y_list_noise)\n",
    "\n",
    "scales = harr_scale_range((1.0/6.0), 10)\n",
    "transform_coefficients = continuous_transform_harr(noisy_data[1], scales)\n",
    "\n",
    "end_time = time.perf_counter()\n",
    "print(\"Time Elapsed: \"+ str(end_time-start_time))\n",
    "\n",
    "Z = transform_coefficients\n",
    "\n",
    "plt.figure(figsize=(24,13))\n",
    "plt.subplot(2, 1, 1)\n",
    "plt.plot(x_list, noisy_data[1])\n",
    "plt.xlabel(\"Year\")\n",
    "plt.ylabel(\"Z-score\")\n",
    "title_string_raw = \"Red Noise w/ r =\" + str(r) + \" and std_dev = \" + str(std_dev)\n",
    "plt.title(title_string_raw)\n",
    "\n",
    "plt.subplot(2, 1, 2)\n",
    "plt.contourf(x_list, scales, Z)\n",
    "plt.xlabel(\"Year\")\n",
    "plt.ylabel(\"Scale\")\n",
    "plt.title(\"Harr Wavelet Coefficients, Raw Data\")\n",
    "cbar = plt.colorbar()\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time Elapsed: 0.40622502551195794\n"
     ]
    }
   ],
   "source": [
    "# Harr wavelet on line w/ slope 5 globally\n",
    "start_time = time.perf_counter()\n",
    "\n",
    "x_list = np.linspace(0, 115.75, 460)\n",
    "slope = 5.0\n",
    "y_list_values = line_generator(-2, slope, x_list)\n",
    "\n",
    "#station = select_id(62658, StateID_objects)\n",
    "#min_winter_temps_list = dict_to_list(station.max_temp_winter())\n",
    "#N = len(min_winter_temps_list)\n",
    "#x_list = np.linspace(1900, 2014+0.75, N, endpoint=True)\n",
    "scales = harr_scale_range((1.0/6.0), 10)\n",
    "transform_coefficients = continuous_transform_harr(y_list_values, scales)\n",
    "\n",
    "end_time = time.perf_counter()\n",
    "print(\"Time Elapsed: \"+ str(end_time-start_time))\n",
    "\n",
    "Z = transform_coefficients\n",
    "\n",
    "plt.figure(figsize=(24,13))\n",
    "plt.subplot(2, 1, 1)\n",
    "plt.plot(x_list, y_list_values)\n",
    "plt.xlabel(\"Year\")\n",
    "plt.ylabel(\"Z-score\")\n",
    "title_string_raw = \"Line w/ slope: \" + str(slope)\n",
    "plt.title(title_string_raw)\n",
    "\n",
    "plt.subplot(2, 1, 2)\n",
    "plt.contourf(x_list, scales, Z)\n",
    "plt.xlabel(\"Year\")\n",
    "plt.ylabel(\"Scale\")\n",
    "plt.title(\"Harr Wavelet Coefficients, Raw Data\")\n",
    "cbar = plt.colorbar()\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "460\n",
      "Time Elapsed: 0.4119696699576707\n"
     ]
    }
   ],
   "source": [
    "# Harr wavelet on line w/ slope 5 for first half, slope -5 for second half\n",
    "start_time = time.perf_counter()\n",
    "\n",
    "x_list = np.linspace(0, 115.75, 460)\n",
    "slope1 = 5.0\n",
    "slope2 = -5.0\n",
    "y_list_values_1half = line_generator(0, slope1, x_list[:230])\n",
    "y_list_values_2half = line_generator(290, slope2, x_list[230:])\n",
    "y_list_values = y_list_values_1half + y_list_values_2half\n",
    "print(len(y_list_values))\n",
    "scales = harr_scale_range((1.0/6.0), 10)\n",
    "transform_coefficients = continuous_transform_harr(y_list_values, scales)\n",
    "\n",
    "end_time = time.perf_counter()\n",
    "print(\"Time Elapsed: \"+ str(end_time-start_time))\n",
    "\n",
    "Z = transform_coefficients\n",
    "\n",
    "plt.figure(figsize=(24,13))\n",
    "plt.subplot(2, 1, 1)\n",
    "plt.plot(x_list, y_list_values)\n",
    "plt.xlabel(\"Year\")\n",
    "plt.ylabel(\"Z-score\")\n",
    "title_string_raw = \"Line w/ slope: \" + str(slope)\n",
    "plt.title(title_string_raw)\n",
    "\n",
    "plt.subplot(2, 1, 2)\n",
    "plt.contourf(x_list, scales, Z)\n",
    "plt.xlabel(\"Year\")\n",
    "plt.ylabel(\"Scale\")\n",
    "plt.title(\"Harr Wavelet Coefficients, Raw Data\")\n",
    "cbar = plt.colorbar()\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Random Batch Data #"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "r = 0.7\n",
    "std_dev = 1\n",
    "length = 1380\n",
    "batch_size = 100\n",
    "wavelet_scales = scale_range(0.5, 30)\n",
    "raw_data = no_baseline_red_noise_batch(r, std_dev, length, batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "x_list = np.linspace(0, 114+11.0/12, 1380, endpoint=True)\n",
    "\n",
    "plt.figure(figsize=(24,13))\n",
    "for i in range(0, len(raw_data)):\n",
    "    plt.plot(x_list, raw_data[i])\n",
    "    \n",
    "plt.xlabel(\"Time\")\n",
    "plt.ylabel(\"Noise Value\")\n",
    "title_string_raw = \"First Red Noise Set\"\n",
    "plt.title(title_string_raw)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time Elapsed: 21528.86536401514\n"
     ]
    }
   ],
   "source": [
    "start_time = time.perf_counter()\n",
    "\n",
    "avg_wavelet_coeff = batch_wavelet_transform(raw_data)\n",
    "avg_wavelet_power = wavelet_power_spectra(avg_wavelet_coeff)\n",
    "\n",
    "avg_z_wavelet_coeff = batch_z_score_wavelet_transform(raw_data)\n",
    "avg_z_wavelet_power = wavelet_power_spectra(avg_z_wavelet_coeff)\n",
    "\n",
    "x_list = np.linspace(0, 114+11.0/12, 1380, endpoint=True)\n",
    "\n",
    "end_time = time.perf_counter()\n",
    "print(\"Time Elapsed: \"+ str(end_time-start_time))\n",
    "\n",
    "plt.figure(figsize=(24,13))\n",
    "plt.subplot(2,1,1)\n",
    "plt.contourf(x_list, wavelet_scales, avg_z_wavelet_power)\n",
    "plt.xlabel(\"Time\")\n",
    "plt.ylabel(\"Period [Years]\")\n",
    "plt.title(\"Averaged Morlet Wavelet Coefficients of Raw Data, r=0.7, no baseline, 100 trials\")\n",
    "cbar = plt.colorbar()\n",
    "\n",
    "plt.subplot(2,1,2)\n",
    "plt.contourf(x_list, wavelet_scales, avg_wavelet_power)\n",
    "plt.xlabel(\"Time\")\n",
    "plt.ylabel(\"Period [Years]\")\n",
    "plt.title(\"Corresponding Averaged Morlet Wavelet Coefficients of z-score Data\")\n",
    "cbar = plt.colorbar()\n",
    "\n",
    "plt.tight_layout()\n",
    "save_string = 'nobaseline_rednoise_r07_batch100_with_zscore'\n",
    "plt.savefig(save_string)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Creating Database of Random Signal Power Profiles #"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-4-4140561075ce>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     22\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     23\u001b[0m     \u001b[1;31m# actual data analysis here\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 24\u001b[1;33m     \u001b[0mpower_matrix\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0msim_data_transform\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mwavelet_scales\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     25\u001b[0m     \u001b[0mdf\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpower_profile_dataframe\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpower_matrix\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mwavelet_scales\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     26\u001b[0m     \u001b[0msave_string\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mi\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstrip\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'.csv'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m+\u001b[0m\u001b[1;34m'_POWER_PROFILE.csv'\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Anaconda3\\WAVELETPROJECT\\MWWavelets.ipynb\u001b[0m in \u001b[0;36msim_data_transform\u001b[1;34m(filename, wavelet_scales)\u001b[0m\n",
      "\u001b[1;32mC:\\Anaconda3\\WAVELETPROJECT\\MWWavelets.ipynb\u001b[0m in \u001b[0;36mcontinuous_transform_morlet\u001b[1;34m(time_series, scale_array, f)\u001b[0m\n",
      "\u001b[1;32mC:\\Anaconda3\\WAVELETPROJECT\\MWWavelets.ipynb\u001b[0m in \u001b[0;36mcontinuous_convolution\u001b[1;34m(time_series, wavelet_list)\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# THIS IS TEMPLATE CODE FOR RUNNING OTHER BATCH PROCESSING SETS, DO NOT RUN THIS\n",
    "\n",
    "# doing analysis on all files in subfolder\n",
    "start_time = time.perf_counter()\n",
    "\n",
    "wavelet_scales = list(np.arange(start=0.5, stop=21.5))+list(np.arange(start=21.5, stop=43.5, step=2.0))\n",
    "filenames = os.listdir('C:\\\\Anaconda3\\\\WAVELETPROJECT\\\\Noisy_Sim_Data')\n",
    "#making batches\n",
    "#first_batch = filenames[:2]\n",
    "#second_batch = filenames[2:10]\n",
    "#third_batch = filenames[10:20]\n",
    "#fourth_batch = filenames[20:40]\n",
    "#fifth_batch = filenames[40:64]\n",
    "#have completed fifth batch\n",
    "#sixth_batch = filenames[64:]\n",
    "batch = sixth_batch\n",
    "\n",
    "counter = 1\n",
    "send_email('Data Processing Pipeline', 'Starting batch, size: '+str(len(batch)))\n",
    "\n",
    "for i in batch:\n",
    "    counter += 1\n",
    "    iter_start = time.perf_counter()\n",
    "    \n",
    "    # actual data analysis here\n",
    "    power_matrix = sim_data_transform(i, wavelet_scales)\n",
    "    df = power_profile_dataframe(power_matrix, wavelet_scales)\n",
    "    save_string = i.strip('.csv')+'_POWER_PROFILE.csv'\n",
    "    df.to_csv(save_string)\n",
    "    \n",
    "    # email here\n",
    "    if counter%5==0:\n",
    "        iter_end = time.perf_counter()\n",
    "        time_elapsed = str(iter_end-iter_start)\n",
    "        email_message = 'Finished Processing: '+save_string+' in '+time_elapsed+' seconds. Currently on '+str(counter)+'of'+str(len(batch))\n",
    "        email_subject = 'Data Processing Pipeline'\n",
    "        send_email(email_subject, email_message)\n",
    "    \n",
    "end_time = time.perf_counter()\n",
    "batch_elapsed_time = str(end_time-start_time)\n",
    "send_email('Data Processing Pipeline', 'Finished batch in '+batch_elapsed_time+' seconds.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# doing analysis on a sparse set of files in subfolder\n",
    "\n",
    "# wavelet scales were modified so that each file should only take ~13 minutes to process, vs ~21 minutes\n",
    "wavelet_scales = list(np.arange(start=0.5,stop=21.5,step=2.0))+\\\n",
    "    list(np.arange(start=21.5,stop=31.5,step=2.0))+list(np.arange(start=31.5,stop=42.5,step=5.0))\n",
    "filenames = os.listdir('C:\\\\Anaconda3\\\\WAVELETPROJECT\\\\Noisy_Sim_Data')\n",
    "\n",
    "r_list = [0.0+0.1*i for i in range(11)]\n",
    "r_keep = [r_list[0]]+r_list[1::2]\n",
    "std_dev_keep = [.25]+[0.5+0.5*i for i in range(6)]\n",
    "\n",
    "sparse_filenames = []\n",
    "for i in filenames:\n",
    "    name_split = i.strip('.csv').split('_')\n",
    "    if (float(name_split[5]) in r_keep) and (float(name_split[7]) in std_dev_keep):\n",
    "        sparse_filenames.append(i)\n",
    "\n",
    "first_batch = sparse_filenames[:3]\n",
    "second_batch = sparse_filenames[3:7]\n",
    "third_batch = sparse_filenames[7:17]\n",
    "fourth_batch = sparse_filenames[17:28]\n",
    "fifth_batch = sparse_filenames[28:50]\n",
    "sixth_batch = sparse_filenames[50:75]\n",
    "seventh_batch = sparse_filenames[75:125]\n",
    "eigth_batch = sparse_filenames[125:165]\n",
    "ninth_batch = sparse_filenames[165:200]\n",
    "final_batch = sparse_filenames[200:]\n",
    "finished = []\n",
    "#finished ninth batch\n",
    "batch = finished\n",
    "\n",
    "counter = 1\n",
    "send_email('Data Processing Pipeline', 'Starting batch, size: '+str(len(batch)))\n",
    "\n",
    "start_time = time.perf_counter()\n",
    "for i in batch:\n",
    "    counter += 1\n",
    "    iter_start = time.perf_counter()\n",
    "    \n",
    "    # actual data analysis here\n",
    "    power_matrix = sim_data_transform(i, wavelet_scales)\n",
    "    df = power_profile_dataframe(power_matrix, wavelet_scales)\n",
    "    save_string = i.strip('.csv')+'_POWER_PROFILE.csv'\n",
    "    df.to_csv(save_string)\n",
    "    \n",
    "    # email here\n",
    "    if counter%10==0:\n",
    "        iter_end = time.perf_counter()\n",
    "        time_elapsed = str(iter_end-iter_start)\n",
    "        email_message = 'Finished Processing: '+save_string+' in '+time_elapsed+' seconds. Currently on '+str(counter)+'of'+str(len(batch))\n",
    "        email_subject = 'Data Processing Pipeline'\n",
    "        send_email(email_subject, email_message)\n",
    "    \n",
    "end_time = time.perf_counter()\n",
    "batch_elapsed_time = str(end_time-start_time)\n",
    "send_email('Data Processing Pipeline', 'Finished batch in '+batch_elapsed_time+' seconds.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# using this to write template for multiprocessing in Plotting Scripts\n",
    "# MULTIPROCESSING IS MESSY IN JUPYTER, DON'T USE\n",
    "\"\"\"\n",
    "import multiprocessing\n",
    "\n",
    "wavelet_scales = list(np.arange(start=0.5,stop=21.5,step=2.0))+\\\n",
    "    list(np.arange(start=21.5,stop=31.5,step=2.0))+list(np.arange(start=31.5,stop=42.5,step=5.0))\n",
    "filenames = os.listdir('C:\\\\Anaconda3\\\\WAVELETPROJECT\\\\Noisy_Sim_Data')\n",
    "\n",
    "r_list = [0.0+0.1*i for i in range(11)]\n",
    "r_keep = [r_list[0]]+r_list[1::2]\n",
    "std_dev_keep = [.25]+[0.5+0.5*i for i in range(6)]\n",
    "\n",
    "sparse_filenames = []\n",
    "for i in filenames:\n",
    "    name = i.strip('.csv')\n",
    "    name_split = name.split('_')\n",
    "    if (float(name_split[5]) in r_keep) and (float(name_split[7]) in std_dev_keep):\n",
    "        sparse_filenames.append(i)\n",
    "\n",
    "batch = sparse_filenames[125:129]\n",
    "counter = 1\n",
    "send_email('Data Processing Pipeline', 'Starting batch, size: '+str(len(batch)))\n",
    "\n",
    "start_time = time.perf_counter()\n",
    "iter_start = time.perf_counter()\n",
    "pool = multiprocessing.Pool(processes=4)\n",
    "pool.map(file_to_profile, batch)\n",
    "pool.close()\n",
    "pool.join()\n",
    "    \n",
    "end_time = time.perf_counter()\n",
    "batch_elapsed_time = str(end_time-start_time)\n",
    "send_email('Data Processing Pipeline', 'Finished batch in '+batch_elapsed_time+' seconds.')\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6\n",
      "[(0.5, 0.7554260406340594), (2.5, 0.7741397971677345), (4.5, 0.7529014734873142), (6.5, 0.8552365614032907), (8.5, 0.9344399451244702), (10.5, 1.0544840274177811), (12.5, 1.2258450538516357), (14.5, 1.388473245213372), (16.5, 1.4544389724280185), (18.5, 1.6041734785154413), (20.5, 1.8380572599718714), (21.5, 1.9666680222907473), (23.5, 2.2476051235333174), (25.5, 2.5601905339001743), (27.5, 2.8976472215799776), (29.5, 3.2581058915373875), (31.5, 3.603181722231946), (36.5, 4.847183375260755), (41.5, 5.586628975835314)]\n"
     ]
    }
   ],
   "source": [
    "# graphing profiles\n",
    "test_profiles = os.listdir('C:\\\\Anaconda3\\\\WAVELETPROJECT\\\\Noisy_Sim_Profiles')[::50]\n",
    "print(len(test_profiles))\n",
    "test_profile = load_profile(test_profiles[0])\n",
    "print(test_profile)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "scales, avg_pow = zip(*test_profile)\n",
    "\n",
    "plt.figure(figsize=(10,14))\n",
    "N = len(test_profiles)\n",
    "for i in range(N):\n",
    "    scales, avg_pow = zip(*load_profile(test_profiles[i]))\n",
    "    plt.subplot(N, 1,i+1)\n",
    "    plt.plot(scales, avg_pow)\n",
    "    plt.xlabel(\"Scale\")\n",
    "    plt.xlim(0, 42)\n",
    "    plt.ylabel(\"Avg Wavelet Power\")\n",
    "    title_string_raw = test_profiles[i]\n",
    "    plt.title(title_string_raw)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# creating coefficients for z-scored data\n",
    "data = average_StateID_series(StateID_objects)\n",
    "west_data = average_StateID_series(Appalachian_StateID_objects[0])\n",
    "east_data = average_StateID_series(Appalachian_StateID_objects[1])\n",
    "\n",
    "wavelet_scales = list(np.arange(start=0.5,stop=21.5,step=2.0))+\\\n",
    "    list(np.arange(start=21.5,stop=31.5,step=2.0))+list(np.arange(start=31.5,stop=42.5,step=5.0))\n",
    "    \n",
    "wvlt_coeff_maxtemp = continuous_transform_morlet(data[0], wavelet_scales, 2*np.pi)\n",
    "wvlt_coeff_mintemp = continuous_transform_morlet(data[1], wavelet_scales, 2*np.pi)\n",
    "wvlt_coeff_precip = continuous_transform_morlet(data[2], wavelet_scales, 2*np.pi)\n",
    "wvlt_coeff_nei = continuous_transform_morlet(data[3], wavelet_scales, 2*np.pi)\n",
    "\n",
    "west_coeff_maxtemp = continuous_transform_morlet(west_data[0], wavelet_scales, 2*np.pi)\n",
    "west_coeff_mintemp = continuous_transform_morlet(west_data[1], wavelet_scales, 2*np.pi)\n",
    "west_coeff_precip = continuous_transform_morlet(west_data[2], wavelet_scales, 2*np.pi)\n",
    "west_coeff_nei = continuous_transform_morlet(west_data[3], wavelet_scales, 2*np.pi)\n",
    "\n",
    "east_coeff_maxtemp = continuous_transform_morlet(east_data[0], wavelet_scales, 2*np.pi)\n",
    "east_coeff_mintemp = continuous_transform_morlet(east_data[1], wavelet_scales, 2*np.pi)\n",
    "east_coeff_precip = continuous_transform_morlet(east_data[2], wavelet_scales, 2*np.pi)\n",
    "east_coeff_nei = continuous_transform_morlet(east_data[3], wavelet_scales, 2*np.pi)\n",
    "\n",
    "send_email('Processing z-scored data', 'Completed processing z-scored data')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "MWWavelets.ipynb:85: ComplexWarning: Casting complex values to real discards the imaginary part\n",
      "  \"Year: 1901   Value: -9999.0\\n\",\n"
     ]
    }
   ],
   "source": [
    "# creating profiles from z-scored data above\n",
    "base = ['all_', 'west_', 'east_']\n",
    "types = ['maxt_', 'mint_', 'precip_', 'nei_']\n",
    "end = '_POWER_PROFILE.csv'\n",
    "\n",
    "wavelet_scales = list(np.arange(start=0.5,stop=21.5,step=2.0))+\\\n",
    "    list(np.arange(start=21.5,stop=31.5,step=2.0))+list(np.arange(start=31.5,stop=42.5,step=5.0))\n",
    "wvlt_matrices = [[wvlt_coeff_maxtemp, wvlt_coeff_mintemp, wvlt_coeff_precip, wvlt_coeff_nei], \\\n",
    "                [west_coeff_maxtemp, west_coeff_mintemp, west_coeff_precip, west_coeff_nei], \\\n",
    "                [east_coeff_maxtemp, east_coeff_mintemp, east_coeff_precip, east_coeff_nei]]\n",
    "\n",
    "for i in range(3):\n",
    "    for j in range(4):\n",
    "        df = power_profile_dataframe(wvlt_matrices[i][j], wavelet_scales)\n",
    "        save_string = base[i]+types[j]+end\n",
    "        df.to_csv(save_string)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Changelog\n",
    "3/13/17 Split from NE Climate Database to condense methods w/o plotting scripts\n",
    "- Applied Harr wavelet on line w/ slope 5 for 1st half, slope -5 for second half\n",
    "\n",
    "3/29/17 \n",
    "- Running first set of random batch data\n",
    "\n",
    "3/31/17\n",
    "- Ran first full set of 100 batch random data, with no baseline and r = 0.7\n",
    "\n",
    "4/18/17\n",
    "- Performed wavelet transforms of sorted Appalachian mountain data, plotted coefficients\n",
    "\n",
    "8/26/17\n",
    "- moved bata data analysis processing to this file, performing power profile analysis here\n",
    "\n",
    "9/1/17\n",
    "- plotting profiles"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
